{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "# In[1]:\n",
    "\n",
    "\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\"\n",
    "\n",
    "from itertools import chain\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from IPython.core.debugger import set_trace\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "from natsort import natsorted\n",
    "import collections\n",
    "import skimage\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics.regression import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.helper import predefined_split\n",
    "from sklearn.metrics.regression import mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\n",
    "from skorch import callbacks\n",
    "\n",
    "from dask.distributed import Client\n",
    "from sklearn.externals import joblib\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "plt.ion()\n",
    "%matplotlib inline\n",
    "\n",
    "# # Check cuda.is_available ?\n",
    "\n",
    "# In[2]:\n",
    "\n",
    "\n",
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"cuda_available : {}, device : {}\".format(cuda_available, device))\n",
    "\n",
    "\n",
    "# # Define Dataset & DataLoader\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "MAXLEN = 300\n",
    "FPS = 24.0\n",
    "\n",
    "def drop_huge_seq(input_df, save_path=\"./preprocess/example_data/person_detection_and_tracking_results_drop.pkl\"):\n",
    "    if os.path.exists(save_path):\n",
    "        print('Already dropped! Return...')\n",
    "        return\n",
    "    \n",
    "    vids = list(set(input_df.vids))\n",
    "\n",
    "    for i in tqdm(range(len(vids)), desc='DropInputSeq '):\n",
    "        slice_df = input_df.loc[input_df.vids==vids[i]]\n",
    "        if slice_df.values.shape[0] > MAXLEN:\n",
    "            input_df.iloc[slice_df.index] = np.nan * np.ones_like(slice_df.values)\n",
    "\n",
    "    # drop Nans !\n",
    "    res_df = input_df.dropna()\n",
    "    res_df.to_pickle(\"./preprocess/example_data/person_detection_and_tracking_results_drop.pkl\")\n",
    "\n",
    "input_df = pd.read_csv('./preprocess/example_data/person_detection_and_tracking_results.csv',\n",
    "                       sep='\\t', names=['vids', 'idx', 'pos'])\n",
    "    \n",
    "# drop huge seq\n",
    "drop_huge_seq(input_df, save_path=\"./preprocess/example_data/person_detection_and_tracking_results_drop.pkl\")\n",
    "\n",
    "\n",
    "# In[4]:\n",
    "\n",
    "\n",
    "df = pd.read_pickle('./preprocess/example_data/person_detection_and_tracking_results_drop.pkl')\n",
    "len(list(set(df.vids)))\n",
    "\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "df = pd.read_pickle(\"./preprocess/data/targets_dataframe.pkl\")\n",
    "target_columns = df.columns.values[:-2]\n",
    "# target_columns = ['Toe In / Out/L', 'Toe In / Out/R']\n",
    "\n",
    "\n",
    "# In[6]:\n",
    "\n",
    "\n",
    "def pid2vid(pid):\n",
    "    num, test_id, trial_id = pid.split('_')\n",
    "    return '_'.join([num, 'test', test_id, 'trial', trial_id])\n",
    "    \n",
    "\n",
    "def vid2pid(vid):\n",
    "    split = vid.split('_')\n",
    "    return '_'.join([split[0], split[2], split[4]])\n",
    "\n",
    "\n",
    "\n",
    "class GAITDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 X, y, scaler, frame_home=\"/data/GaitData/CroppedFrameArrays\", maxlen=300):\n",
    "        \n",
    "        self.frame_home = frame_home\n",
    "        \n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.vids = [ pid2vid(pid) for pid in self.y.index ]\n",
    "        \n",
    "        self.maxlen = maxlen\n",
    "        \n",
    "        if scaler:\n",
    "            scaled_values = scaler.transform(y)\n",
    "            self.y.loc[:,:] = scaled_values\n",
    "            \n",
    "    def __len__(self):\n",
    "        return len(self.vids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        vid = self.vids[idx]\n",
    "        positions = [ eval(val) for val in self.X.loc[self.X.vids==vid].pos.values ]\n",
    "        \n",
    "        \n",
    "        stacked_arr = np.load(os.path.join(self.frame_home, vid) + '.npy')\n",
    "        \n",
    "        inputs = []        \n",
    "\n",
    "        for cropped in stacked_arr:  \n",
    "            pic = cv2.resize(cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY), (64,64))[:,:,None]\n",
    "            \n",
    "            pic = TF.to_tensor(pic) # scale to [0.0, 1.0]\n",
    "            pic = TF.normalize(pic, (0.5,), (0.5,)).permute(1,2,0).numpy()   # scale to [-1.0, 1.0]\n",
    "            inputs.append(pic)\n",
    "            \n",
    "        targets = self.y.loc[vid2pid(vid)].values\n",
    "\n",
    "        # zero padding\n",
    "        inputs = np.pad(inputs, ((0,self.maxlen-len(inputs)),(0,0),(0,0),(0,0)),\n",
    "                                               'constant', constant_values=0).transpose(3,0,1,2)\n",
    "        \n",
    "        return torch.tensor(inputs, dtype=torch.float32), torch.tensor(inputs, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3d_with_same_padding(nn.Conv3d):\n",
    "    def __init__(self, in_channels,\n",
    "                       out_channels,\n",
    "                       kernel_size,\n",
    "                       stride=1,\n",
    "                       padding=0,\n",
    "                       dilation=1,\n",
    "                       groups=1,\n",
    "                       bias=True,\n",
    "                       padding_type='same'):\n",
    "        \n",
    "        super(Conv3d_with_same_padding, self).__init__(in_channels,\n",
    "                                     out_channels,\n",
    "                                     kernel_size,\n",
    "                                     stride,\n",
    "                                     padding,\n",
    "                                     dilation,\n",
    "                                     groups,\n",
    "                                     bias)\n",
    "        \n",
    "        self.padding_type = padding_type\n",
    "    \n",
    "    def forward(self, x, debug=False):\n",
    "        n,c,d,h,w = x.size()\n",
    "        if self.padding_type == 'same':\n",
    "            padding_need = []\n",
    "            for i,e in enumerate([d,h,w]):\n",
    "                bias = 0.5 if self.stride[i] % 2 == 0 else 0.0\n",
    "                padding_need.append(round((e * (self.stride[i]-1) + self.kernel_size[i] - self.stride[i]) / 2 + bias))\n",
    "            \n",
    "            padding_need = tuple(padding_need)\n",
    "            \n",
    "        if debug:\n",
    "            set_trace()\n",
    "\n",
    "        return F.conv3d(x, self.weight, self.bias, self.stride, \n",
    "                        padding_need, self.dilation, self.groups)\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, C_in, C_out, pool, highway=True):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.pool = pool\n",
    "        self.highway = highway\n",
    "                \n",
    "        stride = 1\n",
    "        \n",
    "        if C_in != C_out:\n",
    "            C = C_out\n",
    "        else:\n",
    "            C = C_in = C_out\n",
    "            \n",
    "        if pool:\n",
    "            # input dimension matchig\n",
    "            self.conv_matching = Conv3d_with_same_padding(C_in, C, kernel_size=1, stride=1, padding_type='same')\n",
    "            self.bn_matching = nn.BatchNorm3d(C)\n",
    "\n",
    "            # for pooling of residual path\n",
    "            stride = 2\n",
    "            self.conv_pool = Conv3d_with_same_padding(C_in, C, kernel_size=1, stride=2, padding_type='same')\n",
    "            self.bn_pool= nn.BatchNorm3d(C)\n",
    "                \n",
    "        # conv_a : reduce number of channels by factor of 4 (output_channel = C/4)\n",
    "        self.conv_a = Conv3d_with_same_padding(C, int(C/4), kernel_size=1, stride=stride, padding_type='same')\n",
    "        self.bn_a = nn.BatchNorm3d(int(C/4))\n",
    "        \n",
    "        # conv_b : more wide receptive field (output_channel = C/4)\n",
    "        self.conv_b = Conv3d_with_same_padding(int(C/4), int(C/4), kernel_size=3, stride=1, padding_type='same')\n",
    "        self.bn_b = nn.BatchNorm3d(int(C/4))\n",
    "        \n",
    "        # conv_c : recover org channel C (output_channel = C)\n",
    "        self.conv_c = Conv3d_with_same_padding(int(C/4), C, kernel_size=1, stride=1, padding_type='same')\n",
    "        self.bn_c = nn.BatchNorm3d(C)\n",
    "        \n",
    "        if highway:\n",
    "            # conv_g : gating for highway network\n",
    "            self.conv_g = Conv3d_with_same_padding(C, C, kernel_size=1, stride=1, padding_type='same')\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x : size = (batch, channels, maxlen, height, width)\n",
    "        '''\n",
    "        \n",
    "        res = x\n",
    "        \n",
    "        if self.pool:\n",
    "            # input dimension matching with 1x1 conv\n",
    "            x = self.conv_matching(x)\n",
    "            x = self.bn_matching(x)\n",
    "            \n",
    "            # pooling of residual path\n",
    "            res = self.conv_pool(res)\n",
    "            res = self.bn_pool(res)\n",
    "        \n",
    "        # conv_a (C/4)\n",
    "        x = self.conv_a(x)\n",
    "        x = self.bn_a(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # conv_b (C/4)\n",
    "        x = self.conv_b(x)\n",
    "        x = self.bn_b(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # conv_c (C)\n",
    "        x = self.conv_c(x)\n",
    "        x = self.bn_c(x)\n",
    "        \n",
    "        if self.highway:\n",
    "            # gating mechanism from \"highway network\"\n",
    "            \n",
    "            # gating factors controll intensity between x and f(x)\n",
    "            # gating = 1.0 (short circuit) --> output is identity (same as initial input)\n",
    "            # gating = 0.0 (open circuit)--> output is f(x) (case of non-residual network)\n",
    "            gating = torch.sigmoid(self.conv_g(x))\n",
    "            \n",
    "            # apply gating mechanism\n",
    "            x = gating * res + (1.0 - gating) * F.relu(x)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            # normal residual ops (addition)\n",
    "            x = F.relu(x) + res\n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "# In[ ]:\n",
    "\n",
    "\n",
    "class View(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "class GAP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAP, self).__init__()\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        \n",
    "            x : size = (N,C,D,H,W)\n",
    "        '''\n",
    "        set_trace()\n",
    "        return torch.mean(x, (2,3,4))\n",
    "\n",
    "class HighWay(nn.Module):\n",
    "    def __init__(self, input_channel=1, \n",
    "                 num_layers = [3,4,6], num_filters = [64,128,256]):\n",
    "        \n",
    "        super(HighWay, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.num_filters = num_filters\n",
    "\n",
    "        def res_blocks(residual_blocks, num_layers, num_filters, block_ix, pool_first_layer=True):\n",
    "            block_layers = num_layers[block_ix]\n",
    "\n",
    "            for i in range(block_layers):\n",
    "                # default values\n",
    "                pool = False\n",
    "                block_filters = num_filters[block_ix]\n",
    "                \n",
    "                C_in = C_out = block_filters\n",
    "                \n",
    "                if pool_first_layer and i==0:\n",
    "                    pool = True\n",
    "                if i==0 and block_ix > 0:\n",
    "                    C_in = num_filters[block_ix-1]\n",
    "                    \n",
    "                print(f\"layer : {i}, block : {block_ix}, C_in/C_out : {C_in}/{C_out}\")\n",
    "                residual_blocks.append(ResidualBlock(C_in=C_in, C_out=C_out,pool=pool, highway=True))\n",
    "                \n",
    "        residual_blocks = []\n",
    "\n",
    "        for i in range(len(num_layers)):\n",
    "            pool_first_layer = True\n",
    "            if i == 0:\n",
    "                pool_first_layer = False\n",
    "            res_blocks(residual_blocks, num_layers=num_layers, num_filters=num_filters, block_ix=i,\n",
    "                       pool_first_layer=pool_first_layer)\n",
    "        \n",
    "        \n",
    "        nn.ReLU\n",
    "        self.model = nn.Sequential(nn.Conv3d(input_channel, num_filters[0], kernel_size=(3,7,7), stride=(1,1,1)),\n",
    "                                   nn.BatchNorm3d(num_filters[0]), \n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Conv3d(num_filters[0], num_filters[1], kernel_size=3, stride=2),\n",
    "                                   nn.BatchNorm3d(num_filters[1]), \n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool3d(kernel_size=(3,), stride=2),\n",
    "                                   nn.Conv3d(num_filters[1], num_filters[2], kernel_size=3, stride=2),\n",
    "                                   nn.BatchNorm3d(num_filters[2]), \n",
    "                                   nn.ReLU(),\n",
    "                                   #*residual_blocks,\n",
    "                                   GAP(),\n",
    "                                   nn.Linear(num_filters[-1], 17)\n",
    "                                   )\n",
    "\n",
    "    def forward(self, img):\n",
    "        '''\n",
    "            img : size = (batch, input_channel, maxlen, height, width)\n",
    "        '''\n",
    "\n",
    "        return self.model(img)\n",
    "    \n",
    "\n",
    "    \n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_filters = [1,32,64,128,256]):\n",
    "        \n",
    "        super(Encoder, self).__init__()\n",
    "        \n",
    "        \n",
    "        self.encode = nn.Sequential(\n",
    "            # b, 256, 150, 32, 32\n",
    "            nn.Conv3d(num_filters[0], num_filters[1], kernel_size=4, stride=2, padding=1, bias=False), # ()\n",
    "            nn.BatchNorm3d(num_filters[1]), \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # b, 128, 75, 16, 16\n",
    "            nn.Conv3d(num_filters[1], num_filters[2], kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(num_filters[2]), \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # b, 128, 25, 8, 8\n",
    "            nn.MaxPool3d(kernel_size=(5,4,4), stride=(3,2,2), padding=1),\n",
    "            \n",
    "            # b, 64, 8, 4, 4\n",
    "            nn.Conv3d(num_filters[2], num_filters[3], kernel_size=(6,4,4), stride=(3,2,2), padding=1, bias=False),\n",
    "            nn.BatchNorm3d(num_filters[3]), \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # b, 32, 4, 2, 2\n",
    "            nn.Conv3d(num_filters[3], num_filters[4], kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm3d(num_filters[4]), \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "         )\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x : size = (B, C, D, H, W)\n",
    "        '''\n",
    "        return self.encode(x)\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_filters = [256,128,64,32,1]):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.decode = nn.Sequential(\n",
    "            # b, 32, 4, 2, 2\n",
    "            nn.ConvTranspose3d(num_filters[0], num_filters[0], kernel_size=1, stride=1),\n",
    "            nn.BatchNorm3d(num_filters[0]), \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # b, 64, 8, 4, 4\n",
    "            nn.ConvTranspose3d(num_filters[0], num_filters[1], kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(num_filters[1]), \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # b, 128, 25, 8, 8\n",
    "            nn.ConvTranspose3d(num_filters[1], num_filters[2], kernel_size=(6,4,4), stride=(3,2,2), padding=(1,1,1)),\n",
    "            nn.BatchNorm3d(num_filters[2]), \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # b, 128, 75, 16, 16\n",
    "            nn.ConvTranspose3d(num_filters[2], num_filters[2], kernel_size=(5,4,4), stride=(3,2,2), padding=(1,1,1)),\n",
    "            nn.BatchNorm3d(num_filters[2]), \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # b, 256, 150, 32, 32\n",
    "            nn.ConvTranspose3d(num_filters[2], num_filters[3], kernel_size=4, stride=2, padding=1),\n",
    "            nn.BatchNorm3d(num_filters[3]), \n",
    "            nn.ReLU(True),\n",
    "            \n",
    "            # b, 1, 300, 64, 64\n",
    "            nn.ConvTranspose3d(num_filters[3], num_filters[4], kernel_size=4, stride=2, padding=1),\n",
    "            nn.Tanh()\n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x : size = (B, C, D, H, W)\n",
    "        '''\n",
    "        return self.decode(x)\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        \n",
    "        self.encoder = Encoder()\n",
    "        self.decoder = Decoder()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        encoded = self.encoder(X)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded  # <- return a tuple of two values\n",
    "    \n",
    "    \n",
    "class AutoEncoderNet(NeuralNetRegressor):\n",
    "    def get_loss(self, y_pred, y_true, *args, **kwargs):\n",
    "        decoded, encoded = y_pred  # <- unpack the tuple that was returned by `forward`\n",
    "        loss_reconstruction = super(AutoEncoderNet, self).get_loss(decoded, y_true, *args, **kwargs)\n",
    "        loss_l1 = 1e-3 * torch.abs(encoded).sum()\n",
    "        \n",
    "        return loss_reconstruction + loss_l1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def filter_input_df_with_vids(df, vids):\n",
    "    return df[df['vids'].isin(vids)]\n",
    "\n",
    "def filter_target_df_with_vids(df, vids):\n",
    "    target_ids = [ vid2pid(vid) for vid in vids ]\n",
    "    return df.loc[target_ids]\n",
    "\n",
    "def split_dataset_with_vids(input_df, target_df, vids, test_size=0.3, random_state=42):\n",
    "    train_vids, test_vids = train_test_split(vids, test_size=test_size, random_state=random_state)\n",
    "\n",
    "    train_X, train_y = filter_input_df_with_vids(input_df,train_vids), filter_target_df_with_vids(target_df,train_vids)\n",
    "    test_X, test_y = filter_input_df_with_vids(input_df,test_vids), filter_target_df_with_vids(target_df, test_vids)\n",
    "        \n",
    "    return train_X, train_y, train_vids, test_X, test_y, test_vids\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred):\n",
    "    ape = []\n",
    "    zero_cnt = 0\n",
    "    for true,pred in zip(y_true, y_pred):\n",
    "        if 0.0 not in true:\n",
    "            ape.append(np.abs((true-pred)/true))  \n",
    "        else:\n",
    "            zero_cnt += 1\n",
    "    \n",
    "    return np.mean(ape), zero_cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Callback\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "def to_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = np.clip(x, 0.0, 1.0)\n",
    "    x = 255*x\n",
    "    return x.astype(np.uint8)\n",
    "\n",
    "def to_tensor_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.view(x.size(0), 1, 64, 64)\n",
    "    return x\n",
    "\n",
    "class SaveResults(Callback):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        \n",
    "    def on_epoch_end(self, net, **kwargs):        \n",
    "        for name in ['train', 'valid']:\n",
    "            dataset = kwargs['dataset_'+name]\n",
    "            rand_ix = np.random.randint(len(dataset))\n",
    "            X,y = dataset[rand_ix]\n",
    "            \n",
    "            save_dir = os.path.join(self.path, name)\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            \n",
    "            # target img\n",
    "            y = y.numpy().transpose(1,2,3,0)  # (maxlen,h,w,3)\n",
    "            \n",
    "            # predicted img\n",
    "            pred = net.predict(X[None,:])[0].transpose(1,2,3,0) # (maxlen,h,w,3)\n",
    "            \n",
    "            for sub_name,pic in zip(['target', 'pred'], [y,pred]):\n",
    "                pic = to_tensor_img(torch.from_numpy(pic))\n",
    "                save_image(pic, os.path.join(save_dir,sub_name+'.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# dataset path\n",
    "input_file = \"./preprocess/example_data/person_detection_and_tracking_results_drop.pkl\"\n",
    "target_file = \"./preprocess/data/targets_dataframe.pkl\"\n",
    "\n",
    "input_df = pd.read_pickle(input_file)\n",
    "target_df = pd.read_pickle(target_file)[target_columns]\n",
    "\n",
    "possible_vids = list(set(input_df.vids))[:100]\n",
    "train_X, train_y, train_vids, test_X, test_y, test_vids = split_dataset_with_vids(input_df, target_df, possible_vids, test_size=0.3, random_state=42)\n",
    "\n",
    "# target scaler\n",
    "# scaler = StandardScaler()\n",
    "# train_y.loc[:,:] = scaler.fit_transform(train_y.values)\n",
    "\n",
    "scaler = None\n",
    "\n",
    "# holdouf test set for final evaluation\n",
    "test_dataset = GAITDataset(test_X, test_y, scaler)\n",
    "test_batcher = DataLoader(test_dataset,batch_size=10, shuffle=False, num_workers=16)\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5)\n",
    "\n",
    "train_vids = np.array(train_vids)\n",
    "\n",
    "\n",
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "class MyCriterion(_Loss):\n",
    "    def __init__(self):\n",
    "        super(MyCriterion, self).__init__()\n",
    "    \n",
    "    def forward(self, x, y):\n",
    "        valid_mask = ~(y.view(y.size(0),MAXLEN,-1)==0).all(dim=2)\n",
    "        valid_mask = valid_mask.float()\n",
    "        return torch.mean(torch.sum((valid_mask * ((x-y)**2).mean((1,3,4))),1)/torch.sum(valid_mask,1))\n",
    "        \n",
    "    \n",
    "# for parallelism\n",
    "#client = Client('127.0.0.1:8786')\n",
    "\n",
    "# cross validation loop\n",
    "scores = {'MAPE': [], 'MAE': [], 'RMSE': [], 'R2': [], 'Explained variation': []}\n",
    "\n",
    "for train, valid in kf.split(train_vids):\n",
    "    # split trainset with train/valid\n",
    "    train_split, valid_split = train_vids[train], train_vids[valid]\n",
    "    \n",
    "    train_X, train_y = filter_input_df_with_vids(input_df,train_split), filter_target_df_with_vids(target_df,train_split)\n",
    "    valid_X, valid_y = filter_input_df_with_vids(input_df,valid_split), filter_target_df_with_vids(target_df,valid_split)\n",
    "\n",
    "\n",
    "    # dsataset !!\n",
    "    train_dataset = GAITDataset(train_X, train_y, scaler)\n",
    "    valid_dataset = GAITDataset(valid_X, valid_y, scaler)\n",
    "        \n",
    "    # Init net !\n",
    "    net = AutoEncoderNet(\n",
    "        AutoEncoder,\n",
    "        batch_size=10,\n",
    "        max_epochs=100,\n",
    "        lr=1e-3,\n",
    "        optimizer=torch.optim.Adam,\n",
    "        #optimizer__weight_decay=1e-5,\n",
    "        #optimizer__momentum=0.9,\n",
    "        #optimizer__nesterov=True,\n",
    "        criterion=MyCriterion,\n",
    "        device='cuda',\n",
    "        train_split=predefined_split(valid_dataset),\n",
    "        # Shuffle training data on each epoch\n",
    "        iterator_train__shuffle=True,\n",
    "        callbacks=[#('ealy_stop', callbacks.EarlyStopping()),\n",
    "                   #('lr_scheduler', callbacks.LRScheduler(policy='WarmRestartLR', base_period=2)),\n",
    "                   ('prog_bar', callbacks.ProgressBar()),\n",
    "                   ('save_results', SaveResults(path='./results'))\n",
    "                   ],\n",
    "    \n",
    "    )\n",
    "    \n",
    "    #with joblib.parallel_backend('dask'):\n",
    "    # fit with train set\n",
    "    net.fit(train_dataset, y=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('MAE :', mean_absolute_error(y_true, y_pred, multioutput='raw_values'))\n",
    "print('MSE :', mean_squared_error(y_true, y_pred, multioutput='raw_values'))\n",
    "print('RMSE :', np.sqrt(mean_squared_error(y_true, y_pred, multioutput='raw_values')))\n",
    "print('R^2 : ', r2_score(y_true, y_pred, multioutput='variance_weighted'))\n",
    "print('Explained variation : ',explained_variance_score(y_true, y_pred, multioutput='variance_weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "y_true = []\n",
    "\n",
    "train_batcher = DataLoader(train_dataset,batch_size=10, shuffle=False, num_workers=16)\n",
    "\n",
    "for b in iter(train_batcher):\n",
    "    X_test, y_test = b\n",
    "    y_pred.append(net.predict(X_test.numpy()))\n",
    "    y_true.append(y_test.numpy())\n",
    "\n",
    "y_pred = np.concatenate(y_pred, axis=0)\n",
    "y_true = np.concatenate(y_true, axis=0)\n",
    "\n",
    "if scaler:\n",
    "    y_pred = scaler.inverse_transform(y_pred)\n",
    "    y_true = scaler.inverse_transform(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for ii in range(17):\n",
    "    xx = np.linspace(min(y_true[:,ii]), max(y_true[:,ii]))\n",
    "    plt.scatter(y_pred[:,ii], y_true[:,ii])\n",
    "    plt.plot(xx,xx)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.inverse_transform(train_y.values).mean(axis=0))\n",
    "print(scaler.inverse_transform(train_y.values).std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.inverse_transform(test_y.values).mean(axis=0))\n",
    "print(scaler.inverse_transform(test_y.values).std(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_olivetti_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olivetti = fetch_olivetti_faces()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olivetti['data'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "olivetti['target'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_linnerud\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "\n",
    "linnerud = load_linnerud()\n",
    "\n",
    "X = linnerud.data\n",
    "Y = linnerud.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MultiOutputRegressor(GradientBoostingRegressor(), n_jobs=-1)\n",
    "model.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
