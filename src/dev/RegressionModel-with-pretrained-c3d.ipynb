{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0,1,2,3\"\n",
    "\n",
    "from itertools import chain\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from IPython.core.debugger import set_trace\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "import json\n",
    "\n",
    "from natsort import natsorted\n",
    "import collections\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms.functional as TF\n",
    "\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.helper import predefined_split\n",
    "from skorch import callbacks\n",
    "from collections import defaultdict         \n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics.regression import median_absolute_error, mean_absolute_error, mean_squared_error, r2_score, explained_variance_score\n",
    "from sklearn.model_selection import KFold\n",
    "import c3d_wrapper\n",
    "from data_utils import *\n",
    "import models\n",
    "from params import *\n",
    "from statsmodels.graphics.gofplots import qqplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF model for feature extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretrained c3d net( tensorflow )\n",
    "# tf_model = TF_Model()\n",
    "\n",
    "#visualize_conv_featsmap('7157030_test_0_trial_1', tf_model, layer='conv1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Callback\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "def to_tensor_img(x):\n",
    "    x = 0.5 * (x + 1)\n",
    "    x = x.clamp(0, 1)\n",
    "    x = x.permute(0,3,1,2)\n",
    "    x = x.view(x.size(0), 1, 64, 64)\n",
    "    return x\n",
    "\n",
    "class Save_Reconstruction_Results(Callback):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        \n",
    "    def on_epoch_end(self, net, **kwargs):\n",
    "        for name in ['train', 'valid']:\n",
    "            dataset = kwargs['dataset_'+name]\n",
    "            rand_ix = np.random.randint(len(dataset))\n",
    "            X,y = dataset[rand_ix]\n",
    "            \n",
    "            save_dir = os.path.join(self.path, name)\n",
    "            if not os.path.exists(save_dir):\n",
    "                os.makedirs(save_dir)\n",
    "            \n",
    "            # target img\n",
    "            y = y.numpy().transpose(1,2,3,0)  # (maxlen,h,w,3)\n",
    "            \n",
    "            # predicted img\n",
    "            pred = net.predict(X[None,:])[0].transpose(1,2,3,0) # (maxlen,h,w,3)\n",
    "            \n",
    "            for sub_name,pic in zip(['target', 'pred'], [y,pred]):\n",
    "                pic = to_tensor_img(torch.from_numpy(pic))\n",
    "                save_image(pic, os.path.join(save_dir,sub_name+'.png'))\n",
    "\n",
    "                \n",
    "def fetch_samples_from_dataset(dataset):\n",
    "    X = []\n",
    "    Y = []\n",
    "    for item in dataset:\n",
    "        X.append(item[0].numpy())\n",
    "        Y.append(item[1].numpy())\n",
    "        \n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "def check_array(arr):\n",
    "    dim = arr.shape[1]\n",
    "    \n",
    "    # select non-nan rows\n",
    "    arr = arr[(~np.isnan(arr)).all(1)].reshape(-1, dim)    \n",
    "    \n",
    "    # select non-inf rows\n",
    "    arr = arr[(arr!=np.inf).all(1)]\n",
    "    \n",
    "    return arr\n",
    "\n",
    "def mape(y_true, y_pred, scaler=None, reduce_all=True):\n",
    "    if scaler:\n",
    "        # when skorch callbacks is executed for epoch_scoring\n",
    "        y_pred = scaler.inverse_transform(y_pred)\n",
    "        y_true = scaler.inverse_transform(y_true)\n",
    "        \n",
    "    with np.errstate(divide='ignore'):\n",
    "        mape = np.abs((y_true-y_pred)/y_true)\n",
    "\n",
    "    if reduce_all:\n",
    "        return check_array(mape).mean()\n",
    "    else:\n",
    "        return check_array(mape).mean(0)\n",
    "\n",
    "def root_mean_squared_error(y_true, y_pred, reduce_all=True):\n",
    "    if reduce_all:\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    else:\n",
    "        return np.sqrt(mean_squared_error(y_true, y_pred, multioutput='raw_values'))\n",
    "\n",
    "def record_score(y_pred, y_true, phase, columns, group, save_path=\"./scores\"):\n",
    "    ixs = np.array([target_columns.index(col) for col in columns])\n",
    "    \n",
    "    MAE = mean_absolute_error(y_true[:,ixs], y_pred[:,ixs], multioutput='raw_values')\n",
    "    MAPE = mape(y_true[:,ixs], y_pred[:,ixs], reduce_all=False)\n",
    "    R2 = r2_score(y_true[:,ixs], y_pred[:,ixs], multioutput='raw_values')\n",
    "    print(phase, R2.mean())\n",
    "    \n",
    "    MAE_dict = {k:v for k,v in zip(columns, MAE.tolist())}\n",
    "    MAPE_dict = {k:v for k,v in zip(columns, MAPE.tolist())}\n",
    "    R2_dict = {k:v for k,v in zip(columns, R2.tolist())}\n",
    "    \n",
    "    mae_ = f\"MAE : {MAE_dict}\"\n",
    "    mape_ = f\"MAPE : {MAPE_dict}\"\n",
    "    r2_ = f\"R^2 : {R2_dict}\"\n",
    "    \n",
    "    msg = \"\\n\".join([mae_, mape_, r2_]).replace(\"(\",\"\\(\").replace(\")\",\"\\)\")\n",
    "    \n",
    "    log_path = os.path.join(save_path, f'scores_{group}_{phase}.txt')\n",
    "    \n",
    "    os.system(f\"mkdir -p {save_path}\")\n",
    "    os.system(\"echo \\'{}\\' > {}\".format(msg, log_path))\n",
    "    \n",
    "    print(f'resulting scores have been saved at \\\"{log_path}\\\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "class MyCriterion(_Loss):\n",
    "    def __init__(self):\n",
    "        super(MyCriterion, self).__init__()\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        set_trace()\n",
    "        return nn.MSELoss()(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for distributed computing (dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:8786\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>1</li>\n",
       "  <li><b>Cores: </b>56</li>\n",
       "  <li><b>Memory: </b>135.08 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://192.168.0.194:8786' processes=1 cores=56>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "client = Client('127.0.0.1:8786',\n",
    "               serializers=['dask', 'pickle'],\n",
    "                deserializers=['dask', 'msgpack'])\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter search (random search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dask_searchcv import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from skorch.callbacks import Checkpoint, TrainEndCheckpoint\n",
    "\n",
    "# for random number generation\n",
    "from scipy.stats import uniform as sp_uniform\n",
    "from scipy.stats import randint as sp_randint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def hyperparams_search(model, super_class, \n",
    "                       criterion=nn.modules.loss.MSELoss,\n",
    "                       ckpt_dir=None, n_splits=5, train_dataset=None, scaler=None):\n",
    "    \n",
    "    # init net\n",
    "    net = super_class(\n",
    "        model,\n",
    "        max_epochs=50,\n",
    "        optimizer=torch.optim.SGD,\n",
    "        device='cuda',\n",
    "        criterion=criterion,\n",
    "        # Shuffle training data on each epoch\n",
    "        iterator_train__shuffle=True,\n",
    "        callbacks=[('ealy_stop', callbacks.EarlyStopping()),\n",
    "                   ('lr_scheduler', callbacks.LRScheduler(policy='CyclicLR',\n",
    "                                                         mode='exp_range',\n",
    "                                                         base_lr=1e-3,\n",
    "                                                         gamma=0.97)),\n",
    "                   ('MAPE', callbacks.EpochScoring(scoring=make_scorer(mape, \n",
    "                                                                       scaler = data_dict['scaler']), lower_is_better=True)),\n",
    "                   ('R2', callbacks.EpochScoring(scoring='r2', lower_is_better=False)),\n",
    "                   ]\n",
    "    )\n",
    "\n",
    "    params = {'batch_size': sp_randint(4,12),\n",
    "              'callbacks__lr_scheduler__base_lr': sp_uniform(loc=1e-6, scale=1e-2-1e-6),\n",
    "              'callbacks__lr_scheduler__gamma': sp_uniform(loc=0.5, scale=1.0-0.5),\n",
    "              'optimizer__weight_decay': sp_uniform(loc=0.0, scale=1e-2),\n",
    "              'module__num_units': sp_randint(64,256),\n",
    "              'module__drop_rate': sp_uniform(loc=0.0, scale=0.5),\n",
    "             }\n",
    "    \n",
    "    search = RandomizedSearchCV(net, params, refit=True, cv=n_splits,n_iter=30, iid=False,\n",
    "                                scoring=make_scorer(r2_score, multioutput='variance_weighted'))\n",
    "    \n",
    "    X, y_true = fetch_samples_from_dataset(train_dataset)\n",
    "    \n",
    "    search.fit(X, y_true)  \n",
    "    \n",
    "    os.system(f'mkdir -p {ckpt_dir}')\n",
    "    \n",
    "    print(f'save best model to {ckpt_dir}...!')\n",
    "    \n",
    "    search.best_estimator_.save_params(\n",
    "        f_params=os.path.join(ckpt_dir, 'params.pt'),\n",
    "        f_optimizer=os.path.join(ckpt_dir, 'optimizer.pt'),\n",
    "        f_history=os.path.join(ckpt_dir, 'history.json'))\n",
    "    \n",
    "    # save best params also !\n",
    "    json.dump(search.best_params_, open(os.path.join(ckpt_dir, 'best_params.json'), 'w'))\n",
    "    \n",
    "    return search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "task = 'regression@pretrained'\n",
    "\n",
    "input_file = \"../../preprocess/data/person_detection_and_tracking_results_drop.pkl\"\n",
    "target_file = \"../../preprocess/data/targets_dataframe.pkl\"\n",
    "\n",
    "feature_extraction_model=None\n",
    "feature_layer='conv5'\n",
    "\n",
    "data_dict = prepare_dataset(input_file, target_file,\n",
    "                            feature_extraction_model=feature_extraction_model, layer=feature_layer)\n",
    "\n",
    "train_dataset = dataset_init(task,\n",
    "                            data_dict['train_X'], data_dict['train_y'],\n",
    "                            scaler=data_dict['scaler'], name='train')\n",
    "\n",
    "# holdouf testset for final evaluation\n",
    "test_dataset = dataset_init(task, \n",
    "                            data_dict['test_X'], data_dict['test_y'],\n",
    "                            scaler=data_dict['scaler'], name='test')\n",
    "\n",
    "scaler = data_dict['scaler']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define training configurations & run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "super_class = NeuralNetRegressor\n",
    "\n",
    "if task.split('@')[1]=='fromscratch':\n",
    "    super_class = AutoEncoderNet\n",
    "\n",
    "experiments_dict = {}\n",
    "\n",
    "for name,cr in zip(['MSE', 'MAE', 'Huber'],[nn.modules.loss.MSELoss, nn.modules.loss.L1Loss, nn.modules.loss.SmoothL1Loss]):\n",
    "    search = hyperparams_search(\n",
    "                            model=eval('_'.join(task.split('@')).capitalize()),\n",
    "                            super_class=super_class, criterion=cr,\n",
    "                            ckpt_dir=f'./models/exp_with_{name}_cost',\n",
    "                            train_dataset=train_dataset, scaler=scaler)\n",
    "    experiments_dict[name] = search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performance Evaluation for Testset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def visualize_trend(y_true, y_pred, save_dir, grid_size, figsize, columns, group=None):\n",
    "    \n",
    "    nrow,ncol = grid_size\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows=nrow, ncols=ncol, figsize=figsize)\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "#     for ax,col in zip(axes,columns):\n",
    "        \n",
    "#         ix = target_columns.index(col)\n",
    "        \n",
    "#         sampled_y_true = y_true[:,ix]\n",
    "#         sampled_y_pred = y_pred[:,ix]\n",
    "\n",
    "#         sorted_ixs = np.argsort(sampled_y_true)\n",
    "\n",
    "#         sampled_y_true = sampled_y_true[sorted_ixs]\n",
    "#         sampled_y_pred = sampled_y_pred[sorted_ixs]\n",
    "        \n",
    "#         error = sampled_y_true-sampled_y_pred\n",
    "        \n",
    "#         ax.set_title(col+' trace')\n",
    "#         ax.plot(sampled_y_true, '^', color='orange', label='y_true')\n",
    "#         ax.plot(sampled_y_pred, label='y_pred')\n",
    "#         ax.fill_between(np.arange(len(sampled_y_true)), sampled_y_true-error, sampled_y_true,\n",
    "#         alpha=1, edgecolor='#3F7F4C', facecolor='#7EFF99',\n",
    "#     linewidth=0, label='margin')\n",
    "#         ax.legend()\n",
    "        \n",
    "    for ax, col in zip(axes,columns):\n",
    "        ix = target_columns.index(col)\n",
    "        sns.distplot(y_pred[:,ix], hist=False, label='y_pred', ax=ax)\n",
    "        sns.distplot(y_true[:,ix], hist=False, label='y_true', ax=ax)\n",
    "        ax.set_title(f'Distribution of {col}')\n",
    "        ax.legend()\n",
    "    \n",
    "    fig.tight_layout()\n",
    "\n",
    "#     img_path = os.path.join(save_dir, f'trace_plots_{group}.png')\n",
    "    img_path = os.path.join(save_dir, f'dist_plots_{group}.png')\n",
    "\n",
    "    os.system(f'mkdir -p {save_dir}')\n",
    "\n",
    "    plt.savefig(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measure_performance(test_dataset, phase, ckpt_dir, score_dir, figure_dir, scaler=None):\n",
    "    \n",
    "    f_best_params = os.path.join(ckpt_dir, 'best_params.json')\n",
    "    f_params = os.path.join(ckpt_dir, 'params.pt')\n",
    "    \n",
    "    # best hyperparams dict\n",
    "    best_params = json.load(open(f_best_params))\n",
    "    \n",
    "    # restore net from ckpt\n",
    "    net = NeuralNetRegressor(\n",
    "        module=Regression_pretrained,\n",
    "        device='cuda',\n",
    "        **best_params,\n",
    "    )\n",
    "    net.initialize()  \n",
    "    net.load_params(f_params=f_params)\n",
    "    \n",
    "    X, y_true = fetch_samples_from_dataset(test_dataset)\n",
    "    y_pred = net.predict(X)\n",
    "    \n",
    "    if scaler:\n",
    "        y_pred = scaler.inverse_transform(y_pred)\n",
    "        y_true = scaler.inverse_transform(y_true)\n",
    "    \n",
    "    set_trace()\n",
    "    \n",
    "    record_score(y_pred, y_true, phase, columns=['Cycle Time(sec)/L', 'Cycle Time(sec)/R',\n",
    "                             'Stance Time(sec)/L', 'Stance Time(sec)/R',\n",
    "                             'Double Supp. Time(sec)/L', 'Double Supp. Time(sec)/R',\n",
    "                             'Swing Time(sec)/L', 'Swing Time(sec)/R'],\n",
    "                 group='temporal', save_path=score_dir)\n",
    "    record_score(y_pred, y_true, phase, columns=['Stride Length(cm)/L', 'Stride Length(cm)/R',\n",
    "                            'HH Base Support(cm)/L', 'HH Base Support(cm)/R'],\n",
    "                 group='spatial', save_path=score_dir)\n",
    "    record_score(y_pred, y_true, phase, columns=['Cadence', 'Velocity', 'Functional Amb. Profile'],\n",
    "                   group='etc', save_path=score_dir)\n",
    "\n",
    "    report_lerning_process(columns=target_columns,\n",
    "                           phase=phase, save_dir=figure_dir,\n",
    "                           y_pred=y_pred,\n",
    "                           y_true=y_true)\n",
    "    \n",
    "    # Temporal params\n",
    "    visualize_trend(y_true, y_pred, save_dir=figure_dir, grid_size=(4,2), figsize=(20,20),\n",
    "                    columns=['Cycle Time(sec)/L', 'Cycle Time(sec)/R',\n",
    "                             'Stance Time(sec)/L', 'Stance Time(sec)/R',\n",
    "                             'Double Supp. Time(sec)/L', 'Double Supp. Time(sec)/R',\n",
    "                             'Swing Time(sec)/L', 'Swing Time(sec)/R'],\n",
    "                   group='temporal')\n",
    "    \n",
    "    # Spaitial params\n",
    "    visualize_trend(y_true, y_pred, save_dir=figure_dir, grid_size=(2,2), figsize=(20,11),\n",
    "                    columns=['Stride Length(cm)/L', 'Stride Length(cm)/R',\n",
    "                            'HH Base Support(cm)/L', 'HH Base Support(cm)/R'],\n",
    "                   group='spatial')\n",
    "    \n",
    "    # Etcs\n",
    "    visualize_trend(y_true, y_pred, save_dir=figure_dir, grid_size=(2,2), figsize=(20,11),\n",
    "                    columns=['Cadence', 'Velocity', 'Functional Amb. Profile'],\n",
    "                   group='etc')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set([ s.split('_')[0] for s in train_dataset.y.index ])))\n",
    "print(len(set([ s.split('_')[0] for s in test_dataset.y.index ])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for name in ['MSE', 'MAE', 'Huber']:\n",
    "    measure_performance(test_dataset, phase='test', \n",
    "                         ckpt_dir=f'./models/exp_with_{name}_cost',\n",
    "                         score_dir=f'./scores/exp_with_{name}_cost',\n",
    "                         figure_dir=f'./figures/results/exp_with_{name}_cost',\n",
    "                         scaler=scaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(11,7))\n",
    "plt.xticks(ha='left')\n",
    "err_df.plot.bar(rot=-45, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_df = pd.DataFrame(errs, columns=target_columns, index=['MSE', 'MAE', 'Huber']).T\n",
    "err_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errs = []\n",
    "for name in ['MSE', 'MAE', 'Huber']:\n",
    "    file = f'./scores/exp_with_{name}_cost/test.txt'\n",
    "    for line in open(file):\n",
    "        if line:\n",
    "            err_name, vals = line.replace(' ','').split(':')\n",
    "            if line.replace(' ','').split(':')[0]=='MAE':\n",
    "                errs.append(eval(vals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "VHOME = '/data/GaitData/Video'\n",
    "\n",
    "input_df = pd.read_pickle(input_file)\n",
    "target_df = pd.read_pickle(target_file)\n",
    "\n",
    "def check_yolo_detection_ratio(vids):\n",
    "    logs = []\n",
    "    for vid in tqdm(vids):\n",
    "        video_path = os.path.join(VHOME, vid+'.avi')\n",
    "        s,e = target_df.loc[vid2pid(vid)][['start','end']]\n",
    "        FPS = cv2.VideoCapture(video_path).get(cv2.CAP_PROP_FPS)\n",
    "        detection_ratio = len(set(input_df.loc[input_df.vids==vid].loc[input_df.idx.between(s*FPS,e*FPS)].idx)) / ((e-s)*FPS)\n",
    "        logs.append(detection_ratio)\n",
    "        if detection_ratio>1.0:\n",
    "            return input_df.loc[input_df.vids==vid]\n",
    "    return logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1563/1563 [01:26<00:00, 18.00it/s]\n"
     ]
    }
   ],
   "source": [
    "detection_ratios = check_yolo_detection_ratio(train_dataset.vids+test_dataset.vids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6139399546812756"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(detection_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.91650068, 0.94156211, 0.84871162, 0.80838565, 0.94276475,\n",
       "       0.93686507, 0.90352497, 0.86583896, 0.92417412, 0.9341443 ,\n",
       "       0.92262124, 0.93648697, 0.92296887, 0.91850316, 0.90103823,\n",
       "       0.93427546, 0.94005859, 0.87392951, 0.92054692, 0.93099395,\n",
       "       0.93932673, 0.9375026 , 0.94059778, 0.93985415, 0.94993972,\n",
       "       0.91862352, 0.92174426, 0.90737515, 0.92075107, 0.94173901,\n",
       "       0.70346686, 0.93187996, 0.94771613, 0.90816734, 0.81614672,\n",
       "       0.90824378, 0.93052479, 0.94993972, 0.92553585, 0.91333772,\n",
       "       0.94262681, 0.94569713, 0.94707943, 0.89552605, 0.93964799,\n",
       "       0.94262542, 0.91637467, 0.93620336, 0.86177886, 0.91245691,\n",
       "       0.92297771, 0.92998137, 0.90495145, 0.93167933, 0.85389318,\n",
       "       0.91760712, 0.93236309, 0.93425929, 0.67326946, 0.93537797,\n",
       "       0.85099631, 0.94926661, 0.89650564, 0.84415968, 0.92282189,\n",
       "       0.92384004, 0.88278699, 0.93939622, 0.94776515, 0.89711778,\n",
       "       0.86140851, 0.93642998, 0.94855732, 0.92857446, 0.94716885,\n",
       "       0.86111398, 0.93873889, 0.94847269, 0.80572629, 0.64311874,\n",
       "       0.61393995, 0.83626996, 0.92194904, 0.91681064, 0.88855796,\n",
       "       0.88957404, 0.80542727, 0.90909431, 0.90673951, 0.94901226,\n",
       "       0.93037572, 0.92282189, 0.9126249 , 0.91637272, 0.92088484,\n",
       "       0.92900751, 0.7952655 , 0.90986766, 0.9459496 , 0.92593026])"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = np.array(detection_ratios)\n",
    "arr[arr<0.95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027566341036523924"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-arr).std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6139399546812756"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9992805180270207"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9842435523218075"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027566341036523924"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.588050775364311"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.diff(target_df[['start','end']]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.304"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7.6*0.04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.15/7.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9842435523218075"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(detection_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.027566341036523924"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(detection_ratios)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cnt, bins, _ = plt.hist(detection_ratios, bins=len(detection_ratios)); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9496784808399782"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins[1:][np.where((cnt > 0) & (cnt <len(detection_ratios)*0.1))].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9494319417719386"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bins[:-1][cnt>0].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300.0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnt[cnt<125].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
