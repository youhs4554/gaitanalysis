{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"2,3\"\n",
    "\n",
    "import copy\n",
    "from itertools import chain\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from IPython.core.debugger import set_trace\n",
    "import itertools\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2\n",
    "from natsort import natsorted\n",
    "import collections\n",
    "import skimage\n",
    "from IPython import display\n",
    "import pylab as pl\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torchvision.transforms.functional as TF\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check cuda.is_available ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_available : True, device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"cuda_available : {}, device : {}\".format(cuda_available, device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NULL_token = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already dropped! Return...\n"
     ]
    }
   ],
   "source": [
    "MAXLEN = 300\n",
    "FPS = 24.0\n",
    "\n",
    "def drop_huge_seq(input_df, save_path=\"./preprocess/example_data/person_detection_and_tracking_results_drop.pkl\"):\n",
    "    if os.path.exists(save_path):\n",
    "        print('Already dropped! Return...')\n",
    "        return\n",
    "    \n",
    "    vids = list(set(input_df.vids))\n",
    "\n",
    "    for i in tqdm(range(len(vids)), desc='DropInputSeq '):\n",
    "        slice_df = input_df.loc[input_df.vids==vids[i]]\n",
    "        if slice_df.values.shape[0] > MAXLEN:\n",
    "            input_df.iloc[slice_df.index] = np.nan * np.ones_like(slice_df.values)\n",
    "\n",
    "    # drop Nans !\n",
    "    res_df = input_df.dropna()\n",
    "    res_df.to_pickle(\"./preprocess/example_data/person_detection_and_tracking_results_drop.pkl\")\n",
    "\n",
    "input_df = pd.read_csv('./preprocess/example_data/person_detection_and_tracking_results.csv',\n",
    "                       sep='\\t', names=['vids', 'idx', 'pos'])\n",
    "    \n",
    "# drop huge seq\n",
    "drop_huge_seq(input_df, save_path=\"./preprocess/example_data/person_detection_and_tracking_results_drop.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2806"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle('./preprocess/example_data/person_detection_and_tracking_results_drop.pkl')\n",
    "len(list(set(df.vids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Toe In / Out/L',\n",
       " 'Toe In / Out/R',\n",
       " 'Functional Amb. Profile',\n",
       " 'Stride Length(cm)/L',\n",
       " 'Stride Length(cm)/R',\n",
       " 'Velocity',\n",
       " 'Cadence',\n",
       " 'HH Base Support(cm)/L',\n",
       " 'HH Base Support(cm)/R',\n",
       " 'Cycle Time(sec)/L',\n",
       " 'Cycle Time(sec)/R',\n",
       " 'Stance Time(sec)/L',\n",
       " 'Stance Time(sec)/R',\n",
       " 'Double Supp. Time(sec)/L',\n",
       " 'Double Supp. Time(sec)/R',\n",
       " 'Swing Time(sec)/L',\n",
       " 'Swing Time(sec)/R']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_pickle(\"./preprocess/data/targets_dataframe.pkl\")\n",
    "target_columns = df.columns.values[:-2]\n",
    "\n",
    "# best ordering !\n",
    "target_columns = ['Toe In / Out', 'Functional Amb. Profile', 'Stride Length(cm)', 'Velocity', 'Cadence', 'HH Base Support(cm)', 'Cycle Time(sec)', 'Stance Time(sec)', 'Double Supp. Time(sec)', 'Swing Time(sec)']\n",
    "\n",
    "# target_columns = ['Velocity', 'Functional Amb. Profile',\n",
    "#        'Stride Length(cm)/L', 'Stride Length(cm)/R', \n",
    "#        'Toe In / Out/L', 'Toe In / Out/R']\n",
    "\n",
    "\n",
    "def append_LeftRight(names):\n",
    "    res = []\n",
    "    for n in names:\n",
    "        if n not in ['Velocity', 'Cadence', 'Functional Amb. Profile']:\n",
    "            for s in ['/L','/R']:\n",
    "                res.append(n+s)\n",
    "        else:\n",
    "            res.append(n)\n",
    "    return res\n",
    "\n",
    "\n",
    "target_columns = append_LeftRight(target_columns)\n",
    "\n",
    "# n_cluster = 1\n",
    "\n",
    "# ###\n",
    "# #   Clustering...algorithm\n",
    "# ###\n",
    "\n",
    "# C1_names = ['Velocity', 'Cadence', 'Functional Amb. Profile', 'Swing Time(sec)', 'Stride Length(cm)']\n",
    "# C1_names = ['Swing Time(sec)']\n",
    "\n",
    "# C2_names = ['Cycle Time(sec)', 'HH Base Support(cm)', 'Stance Time(sec)', 'Double Supp. Time(sec)', 'Toe In / Out']\n",
    "\n",
    "# C1_names = append_LeftRight(C1_names)\n",
    "# C2_names = append_LeftRight(C2_names)\n",
    "\n",
    "# stacked_names = [ C1_names ] #, C2_names ]\n",
    "\n",
    "# # merge names\n",
    "# target_columns = C1_names # + C2_names\n",
    "\n",
    "target_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Toe In / Out/L, min : -30.3, max: 50.8, mean : 12.054620726495726, std : 7.921709486042356\n",
      "Toe In / Out/R, min : -50.0, max: 48.1, mean : 13.525373931623932, std : 8.125799403350625\n",
      "Functional Amb. Profile, min : 0.0, max: 100.0, mean : 77.08653846153847, std : 16.70590772158621\n",
      "Stride Length(cm)/L, min : 8.849, max: 189.781, mean : 80.88991292735044, std : 26.987397074454805\n",
      "Stride Length(cm)/R, min : 8.77, max: 184.567, mean : 80.87372061965813, std : 27.034962429470017\n",
      "Velocity, min : 6.1, max: 192.3, mean : 71.53597756410255, std : 27.388498865584125\n",
      "Cadence, min : 19.8, max: 166.0, mean : 106.01842948717949, std : 15.654412223351345\n",
      "HH Base Support(cm)/L, min : 0.658, max: 34.473, mean : 11.686826121794871, std : 3.6154494209679044\n",
      "HH Base Support(cm)/R, min : 0.524, max: 33.939, mean : 11.659943376068377, std : 3.615457982421381\n",
      "Cycle Time(sec)/L, min : 0.716, max: 5.669, mean : 1.1610614316239316, std : 0.25268199524608126\n",
      "Cycle Time(sec)/R, min : 0.719, max: 5.681, mean : 1.161778311965812, std : 0.25499079520034446\n",
      "Stance Time(sec)/L, min : 0.5, max: 4.904, mean : 0.773235576923077, std : 0.22970633846118022\n",
      "Stance Time(sec)/R, min : 0.474, max: 5.02, mean : 0.7735013354700855, std : 0.22825135546130548\n",
      "Double Supp. Time(sec)/L, min : 0.134, max: 4.291, mean : 0.38745486111111116, std : 0.21750179498863342\n",
      "Double Supp. Time(sec)/R, min : 0.138, max: 4.563, mean : 0.3880120192307693, std : 0.21682739266467413\n",
      "Swing Time(sec)/L, min : 0.175, max: 0.863, mean : 0.38785710470085477, std : 0.06204922625650955\n",
      "Swing Time(sec)/R, min : 0.074, max: 1.155, mean : 0.3883084935897437, std : 0.06577303872817719\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(target_columns)):\n",
    "    name = target_columns[i]\n",
    "    print(f'{name}, min : {df[name].min()}, max: {df[name].max()}, mean : {df[name].mean()}, std : {df[name].std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pid2vid(pid):\n",
    "    num, test_id, trial_id = pid.split('_')\n",
    "    return '_'.join([num, 'test', test_id, 'trial', trial_id])\n",
    "    \n",
    "\n",
    "def vid2pid(vid):\n",
    "    split = vid.split('_')\n",
    "    return '_'.join([split[0], split[2], split[4]])\n",
    "        \n",
    "\n",
    "class GAITDataset(Dataset):\n",
    "    def __init__(self,\n",
    "                 frame_home, input_file, target_file,\n",
    "                 phase, split_ratio, normalize_target=True, maxlen=300, r_seed=3):\n",
    "        \n",
    "        self.maxlen = maxlen\n",
    "        self.frame_home = frame_home\n",
    "\n",
    "        # input dataframe\n",
    "        input_df = pd.read_pickle(input_file)\n",
    "        \n",
    "        # target dataframe\n",
    "        target_df = pd.read_pickle(target_file)[target_columns]\n",
    "        \n",
    "        vids = list(set(input_df.vids))\n",
    "        vids = [ v for v in vids if os.path.exists(os.path.join(self.frame_home, v) + '.npy') ]\n",
    "        \n",
    "        # reindex tgt data (to filter-out valid vids)\n",
    "        pids = []\n",
    "        for vid in vids:\n",
    "            pids.append(vid2pid(vid))\n",
    "\n",
    "        target_df = target_df.reindex(pids)\n",
    "        \n",
    "        # remove rows with any 0.0 values\n",
    "        target_df = target_df[(target_df.T!=0).all()]\n",
    "        \n",
    "        # vids without zero values in target df\n",
    "        vids = [ pid2vid(pid) for pid in target_df.index.values ][:160]\n",
    "\n",
    "        if normalize_target:\n",
    "            # target dataframe (minmax scaled)\n",
    "            self.target_scaler = MinMaxScaler(feature_range=(0, 1.0))\n",
    "            scaled_values = self.target_scaler.fit_transform(target_df)\n",
    "            target_df.loc[:,:] = scaled_values\n",
    "        \n",
    "        # add to member\n",
    "        self.input_df = input_df\n",
    "        self.target_df = target_df\n",
    "        \n",
    "        random.seed(r_seed)\n",
    "        random.shuffle(vids)  # shuffle vids inplace, before datasplit\n",
    "        \n",
    "        if phase=='train':\n",
    "            self.vids = vids[:int(len(vids)*split_ratio)]\n",
    "        elif phase=='test':\n",
    "            self.vids = vids[-int(len(vids)*split_ratio):]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.vids)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        vid = self.vids[idx]\n",
    "        positions = [ eval(val) for val in self.input_df.loc[self.input_df.vids==vid].pos.values ]\n",
    "        \n",
    "        \n",
    "        H,W = 480,640\n",
    "        inputs = []\n",
    "        \n",
    "        stacked_arr = np.load(os.path.join(self.frame_home, vid) + '.npy')\n",
    "        \n",
    "        for cropped in stacked_arr:            \n",
    "            # info about cropped_frame\n",
    "            (h,w,_) = cropped.shape\n",
    "            npad = ((((H-h)//2,(H-h)-(H-h)//2), ((W-w)//2,(W-w)-(W-w)//2), (0,0)))\n",
    "\n",
    "            # zero padding around cropped frame\n",
    "            padded = np.pad(cropped, npad, 'constant', constant_values=(0))\n",
    "            \n",
    "            scaled_image = TF.to_tensor(\n",
    "                cv2.resize(\n",
    "                    cv2.cvtColor(cropped, cv2.COLOR_BGR2GRAY)[:,:,None], (112,112)\n",
    "                )\n",
    "            )\n",
    "            normalized_image = TF.normalize(scaled_image, mean=[0.5], std=[0.5])\n",
    "            inputs.append(normalized_image.numpy().transpose(1,2,0))\n",
    "        \n",
    "        pid, _, test_ix, _, trial_ix, *_ = os.path.splitext(vid)[0].split('_')\n",
    "        \n",
    "        target_id = '_'.join([pid, test_ix, trial_ix])\n",
    "        target_data = np.array([NULL_token]+self.target_df.loc[target_id].values.tolist())\n",
    "        \n",
    "        # parse target data\n",
    "        targets = target_data\n",
    "        \n",
    "        # zero padding\n",
    "        inputs = np.pad(inputs, ((0,self.maxlen-len(inputs)),(0,0),(0,0),(0,0)),\n",
    "                                               'constant', constant_values=0).transpose(3,0,1,2)\n",
    "        \n",
    "        sample = {'inputs': torch.tensor(inputs, dtype=torch.float32),\n",
    "                  'targets': torch.tensor(target_data, dtype=torch.float32)\n",
    "                 }\n",
    "        \n",
    "        return sample\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# dataset path\n",
    "input_file = \"./preprocess/example_data/person_detection_and_tracking_results_drop.pkl\"\n",
    "target_file = \"./preprocess/data/targets_dataframe.pkl\"\n",
    "frame_home = \"/data/GaitData/CroppedFrameArrays\"\n",
    "\n",
    "\n",
    "dataset = { phase : GAITDataset(frame_home, input_file, target_file, phase=phase, split_ratio=split_ratio) \\\n",
    "                for phase,split_ratio in zip(['train', 'test'], [0.8, 0.2]) }\n",
    "dataloader = { phase : DataLoader(dataset[phase],\n",
    "                        batch_size=10,\n",
    "                        shuffle=True,\n",
    "                        num_workers=16) \\\n",
    "                    for phase in ['train', 'test'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([18])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['targets'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv3d_with_same_padding(nn.Conv3d):\n",
    "    def __init__(self, in_channels,\n",
    "                       out_channels,\n",
    "                       kernel_size,\n",
    "                       stride=1,\n",
    "                       padding=0,\n",
    "                       dilation=1,\n",
    "                       groups=1,\n",
    "                       bias=True,\n",
    "                       padding_type='same'):\n",
    "        \n",
    "        super(Conv3d_with_same_padding, self).__init__(in_channels,\n",
    "                                     out_channels,\n",
    "                                     kernel_size,\n",
    "                                     stride,\n",
    "                                     padding,\n",
    "                                     dilation,\n",
    "                                     groups,\n",
    "                                     bias)\n",
    "        \n",
    "        self.padding_type = padding_type\n",
    "    \n",
    "    def forward(self, x, debug=False):\n",
    "        n,c,d,h,w = x.size()\n",
    "        if self.padding_type == 'same':\n",
    "            padding_need = []\n",
    "            for i,e in enumerate([d,h,w]):\n",
    "                bias = 0.5 if self.stride[i] % 2 == 0 else 0.0\n",
    "                padding_need.append(round((e * (self.stride[i]-1) + self.kernel_size[i] - self.stride[i]) / 2 + bias))\n",
    "            \n",
    "            padding_need = tuple(padding_need)\n",
    "            \n",
    "        if debug:\n",
    "            set_trace()\n",
    "\n",
    "        return F.conv3d(x, self.weight, self.bias, self.stride, \n",
    "                        padding_need, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, C_in, C_out, pool, highway=True):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.pool = pool\n",
    "        self.highway = highway\n",
    "                \n",
    "        stride = 1\n",
    "        \n",
    "        if C_in != C_out:\n",
    "            C = C_out\n",
    "        else:\n",
    "            C = C_in = C_out\n",
    "            \n",
    "        if pool:\n",
    "            # input dimension matchig\n",
    "            self.conv_matching = Conv3d_with_same_padding(C_in, C, kernel_size=1, stride=1, padding_type='same')\n",
    "            self.bn_matching = nn.BatchNorm3d(C)\n",
    "\n",
    "            # for pooling of residual path\n",
    "            stride = 2\n",
    "            self.conv_pool = Conv3d_with_same_padding(C_in, C, kernel_size=1, stride=2, padding_type='same')\n",
    "            self.bn_pool= nn.BatchNorm3d(C)\n",
    "                \n",
    "        # conv_a : reduce number of channels by factor of 4 (output_channel = C/4)\n",
    "        self.conv_a = Conv3d_with_same_padding(C, int(C/4), kernel_size=1, stride=stride, padding_type='same')\n",
    "        self.bn_a = nn.BatchNorm3d(int(C/4))\n",
    "        \n",
    "        # conv_b : more wide receptive field (output_channel = C/4)\n",
    "        self.conv_b = Conv3d_with_same_padding(int(C/4), int(C/4), kernel_size=3, stride=1, padding_type='same')\n",
    "        self.bn_b = nn.BatchNorm3d(int(C/4))\n",
    "        \n",
    "        # conv_c : recover org channel C (output_channel = C)\n",
    "        self.conv_c = Conv3d_with_same_padding(int(C/4), C, kernel_size=1, stride=1, padding_type='same')\n",
    "        self.bn_c = nn.BatchNorm3d(C)\n",
    "        \n",
    "        if highway:\n",
    "            # conv_g : gating for highway network\n",
    "            self.conv_g = Conv3d_with_same_padding(C, C, kernel_size=1, stride=1, padding_type='same')\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x : size = (batch, channels, maxlen, height, width)\n",
    "        '''\n",
    "        \n",
    "        res = x\n",
    "        \n",
    "        if self.pool:\n",
    "            # input dimension matching with 1x1 conv\n",
    "            x = self.conv_matching(x)\n",
    "            x = self.bn_matching(x)\n",
    "            \n",
    "            # pooling of residual path\n",
    "            res = self.conv_pool(res)\n",
    "            res = self.bn_pool(res)\n",
    "        \n",
    "        # conv_a (C/4)\n",
    "        x = self.conv_a(x)\n",
    "        x = self.bn_a(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # conv_b (C/4)\n",
    "        x = self.conv_b(x)\n",
    "        x = self.bn_b(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # conv_c (C)\n",
    "        x = self.conv_c(x)\n",
    "        x = self.bn_c(x)\n",
    "        \n",
    "        if self.highway:\n",
    "            # gating mechanism from \"highway network\"\n",
    "            \n",
    "            # gating factors controll intensity between x and f(x)\n",
    "            # gating = 1.0 (short circuit) --> output is identity (same as initial input)\n",
    "            # gating = 0.0 (open circuit)--> output is f(x) (case of non-residual network)\n",
    "            gating = torch.sigmoid(self.conv_g(x))\n",
    "            \n",
    "            # apply gating mechanism\n",
    "            x = gating * res + (1.0 - gating) * F.relu(x)\n",
    "\n",
    "            \n",
    "        else:\n",
    "            # normal residual ops (addition)\n",
    "            x = F.relu(x) + res\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer : 0, block : 0, C_in/C_out : 64/64\n",
      "layer : 1, block : 0, C_in/C_out : 64/64\n",
      "layer : 2, block : 0, C_in/C_out : 64/64\n",
      "layer : 0, block : 1, C_in/C_out : 64/64\n",
      "layer : 1, block : 1, C_in/C_out : 64/64\n",
      "layer : 2, block : 1, C_in/C_out : 64/64\n",
      "layer : 0, block : 2, C_in/C_out : 64/128\n",
      "layer : 1, block : 2, C_in/C_out : 128/128\n",
      "layer : 2, block : 2, C_in/C_out : 128/128\n",
      "layer : 3, block : 2, C_in/C_out : 128/128\n",
      "layer : 0, block : 3, C_in/C_out : 128/128\n",
      "layer : 1, block : 3, C_in/C_out : 128/128\n",
      "layer : 2, block : 3, C_in/C_out : 128/128\n",
      "layer : 3, block : 3, C_in/C_out : 128/128\n",
      "layer : 0, block : 4, C_in/C_out : 128/256\n",
      "layer : 1, block : 4, C_in/C_out : 256/256\n",
      "layer : 2, block : 4, C_in/C_out : 256/256\n",
      "layer : 3, block : 4, C_in/C_out : 256/256\n",
      "layer : 4, block : 4, C_in/C_out : 256/256\n",
      "layer : 5, block : 4, C_in/C_out : 256/256\n",
      "layer : 0, block : 5, C_in/C_out : 256/256\n",
      "layer : 1, block : 5, C_in/C_out : 256/256\n",
      "layer : 2, block : 5, C_in/C_out : 256/256\n",
      "layer : 3, block : 5, C_in/C_out : 256/256\n",
      "layer : 4, block : 5, C_in/C_out : 256/256\n",
      "layer : 5, block : 5, C_in/C_out : 256/256\n",
      "layer : 0, block : 6, C_in/C_out : 256/256\n",
      "layer : 1, block : 6, C_in/C_out : 256/256\n",
      "layer : 2, block : 6, C_in/C_out : 256/256\n",
      "layer : 3, block : 6, C_in/C_out : 256/256\n",
      "layer : 4, block : 6, C_in/C_out : 256/256\n",
      "layer : 5, block : 6, C_in/C_out : 256/256\n",
      "layer : 6, block : 6, C_in/C_out : 256/256\n",
      "layer : 7, block : 6, C_in/C_out : 256/256\n",
      "layer : 0, block : 7, C_in/C_out : 256/256\n",
      "layer : 1, block : 7, C_in/C_out : 256/256\n",
      "layer : 2, block : 7, C_in/C_out : 256/256\n",
      "layer : 3, block : 7, C_in/C_out : 256/256\n",
      "layer : 4, block : 7, C_in/C_out : 256/256\n",
      "layer : 5, block : 7, C_in/C_out : 256/256\n",
      "layer : 6, block : 7, C_in/C_out : 256/256\n",
      "layer : 7, block : 7, C_in/C_out : 256/256\n",
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "\n",
    "class GAP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GAP, self).__init__()\n",
    "    def forward(self, x):\n",
    "        '''\n",
    "        \n",
    "            x : size = (N,C,D,H,W)\n",
    "        '''\n",
    "        return torch.mean(x, (2,3,4))\n",
    "\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, in_size=1, hidden_size=30, out_size=1):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.lstm = nn.LSTM(in_size,hidden_size, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, out_size)\n",
    "\n",
    "    def forward(self, x, initial_state):\n",
    "        self.lstm.flatten_parameters()\n",
    "        \n",
    "        length = x.size(1)\n",
    "        \n",
    "        # initial state: (1,1,F), in : (B,T,1), out : (B,T,hidden)\n",
    "        lstm_out, state = self.lstm(x, initial_state)        \n",
    "        out = self.fc(lstm_out).squeeze(-1).t()   # in : (B,T,hidden), out : (B,T,1)\n",
    "        \n",
    "        return out, state\n",
    "\n",
    "class HighWay(nn.Module):\n",
    "    def __init__(self, input_channel, \n",
    "                 num_layers = [3,3,4,4,6,6,8,8], num_filters = [64,64,128,128,256,256,256,256]):\n",
    "        \n",
    "        super(HighWay, self).__init__()\n",
    "        \n",
    "        self.num_layers = num_layers\n",
    "        self.num_filters = num_filters\n",
    "\n",
    "        def res_blocks(residual_blocks, num_layers, num_filters, block_ix, pool_first_layer=True):\n",
    "            block_layers = num_layers[block_ix]\n",
    "\n",
    "            for i in range(block_layers):\n",
    "                # default values\n",
    "                pool = False\n",
    "                block_filters = num_filters[block_ix]\n",
    "                \n",
    "                C_in = C_out = block_filters\n",
    "                \n",
    "                if pool_first_layer and i==0:\n",
    "                    pool = True\n",
    "                if i==0 and block_ix > 0:\n",
    "                    C_in = num_filters[block_ix-1]\n",
    "                    \n",
    "                print(f\"layer : {i}, block : {block_ix}, C_in/C_out : {C_in}/{C_out}\")\n",
    "                residual_blocks.append(ResidualBlock(C_in=C_in, C_out=C_out,pool=pool, highway=True))\n",
    "                \n",
    "        residual_blocks = []\n",
    "\n",
    "        for i in range(len(num_layers)):\n",
    "            pool_first_layer = True\n",
    "            if i == 0:\n",
    "                pool_first_layer = False\n",
    "            res_blocks(residual_blocks, num_layers=num_layers, num_filters=num_filters, block_ix=i,\n",
    "                       pool_first_layer=pool_first_layer)\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.model = nn.Sequential(nn.Conv3d(input_channel, num_filters[0], kernel_size=7, stride=2),\n",
    "                                   nn.BatchNorm3d(num_filters[0]), \n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool3d(kernel_size=(3,), stride=2),\n",
    "                                   nn.Conv3d(num_filters[0], num_filters[0], kernel_size=3, stride=2),\n",
    "                                   nn.BatchNorm3d(num_filters[0]), \n",
    "                                   nn.ReLU(),\n",
    "                                   nn.MaxPool3d(kernel_size=(3,), stride=2),\n",
    "                                   *residual_blocks,\n",
    "                                   GAP(),\n",
    "                                )\n",
    "            \n",
    "    def forward(self, img):\n",
    "        '''\n",
    "            img : size = (batch, input_channel, maxlen, height, width)\n",
    "        '''\n",
    "        \n",
    "        return self.model(img)\n",
    "\n",
    "\n",
    "class TeachingDecode(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(TeachingDecode, self).__init__()\n",
    "    \n",
    "    def forward(self, rnn, decoder_input, initial_state):\n",
    "        '''\n",
    "           decoder_input : size = (batch, time_stamps)\n",
    "        '''\n",
    "        return rnn(decoder_input.view(-1,17,1), initial_state)\n",
    "\n",
    "class GreedyDecode(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GreedyDecode, self).__init__()\n",
    "\n",
    "    def forward(self, rnn, initial_state, length=17):\n",
    "        '''\n",
    "            initial_state : tuple of features from ConvNet, tuple of (batch,1,features)\n",
    "        '''\n",
    "\n",
    "        batch_size = initial_state[0].size(1)\n",
    "\n",
    "        decoded_batch = torch.zeros((batch_size, length), requires_grad=True).to(device)\n",
    "        decoder_input = torch.tensor([[NULL_token] for _ in range(batch_size)]).float().to(device)\n",
    "        hidden = initial_state # init hidden state\n",
    "        \n",
    "        for t in range(length):\n",
    "            out, hidden = rnn(decoder_input.view(-1,1,1), hidden)\n",
    "            \n",
    "            topv, topi = out.data.topk(1, dim=0)  # get candidates\n",
    "            topv = topv.view(-1)\n",
    "            decoded_batch[:, t] = topv\n",
    "\n",
    "            decoder_input = topv.detach().view(-1, 1)\n",
    "            \n",
    "        return decoded_batch, hidden\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_channel, decoder_input_size=1, decoder_output_size=1, length=17):\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        # high-way net\n",
    "        self.hn = HighWay(input_channel)\n",
    "        self.feats_size = feats_size = self.hn.num_filters[-1]\n",
    "\n",
    "        # rnn for decoding\n",
    "        self.rnn = RNN(in_size=decoder_input_size,\n",
    "          hidden_size=feats_size,\n",
    "          out_size=decoder_output_size)\n",
    "\n",
    "        # decoders\n",
    "        self.td = TeachingDecode()\n",
    "        self.gd = GreedyDecode()\n",
    "        self.length = length # maximum length of greedy decoding...\n",
    "\n",
    "    def forward(self, img, decoder_input, greedy=False):\n",
    "                \n",
    "        feats = self.hn(img) # common operation! (i.e. feature extraction)\n",
    "        initial_state = ( feats.view(1,-1,self.feats_size),\n",
    "                          feats.view(1,-1,self.feats_size) )\n",
    "\n",
    "        if greedy:\n",
    "            o,s = self.gd(self.rnn, initial_state, length=self.length)\n",
    "        else:\n",
    "            o,s = self.td(self.rnn, decoder_input, initial_state)\n",
    "            \n",
    "        return o.t(),s\n",
    "        \n",
    "\n",
    "net = Net(input_channel=1, decoder_input_size=1, decoder_output_size=1, length=17).to(device)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "else:\n",
    "    print(\"Single GPU mode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Monitoring functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monitor_lerning_process(info_tuple):    \n",
    "    plt.cla()\n",
    "    \n",
    "    pred_and_gt = { k:[] for k in info_tuple.columns }\n",
    "\n",
    "    for i,col in enumerate(info_tuple.columns):\n",
    "        pred_and_gt[col].append([info_tuple.res[:,i], info_tuple.targets[:,i]])\n",
    "    \n",
    "    data = collections.defaultdict(list)\n",
    "\n",
    "    pp = []\n",
    "    gg = []\n",
    "    for i,col in enumerate(pred_and_gt.keys()):\n",
    "        transposed_data = list(zip(*pred_and_gt[col]))\n",
    "        preds = np.concatenate(transposed_data[0])\n",
    "        gts = np.concatenate(transposed_data[1])\n",
    "\n",
    "        pp.append(preds)\n",
    "        gg.append(gts)\n",
    "\n",
    "        for p,g in zip(preds, gts):\n",
    "            data[\"name\"].append(col)\n",
    "            data[\"pred\"].append(p)\n",
    "            data[\"gt\"].append(g)\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=4, figsize=(20,20))\n",
    "    fig.suptitle(\"Epoch={} / Phase={}\\nLoss={:.8f}\".format(info_tuple.epoch,\n",
    "                                                                      info_tuple.phase,\n",
    "                                                                      info_tuple.avg_loss),\n",
    "                              fontsize=30)\n",
    "    \n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i,col in enumerate(info_tuple.columns):\n",
    "        part_of_df = df.loc[df.name==col]\n",
    "        ax = axes[i]\n",
    "        part_of_df.plot.scatter(x=\"pred\", y=\"gt\", c='green', ax=ax, label='data')\n",
    "        ax.set_title(f'name={col}')\n",
    "    \n",
    "    for i,(preds,gts) in enumerate(zip(pp,gg)):\n",
    "        ax = axes[i]\n",
    "        ax.plot([min(gts), max(gts)], [min(gts), max(gts)], 'r--', label='GT=PRED')\n",
    "        ax.legend()\n",
    "            \n",
    "    history = info_tuple.history    \n",
    "        \n",
    "    ax1, ax2 = axes[len(info_tuple.columns):][:2] # last two axes : plot learning curve (train/test)\n",
    "\n",
    "    for ax,name,color in zip([ax1, ax2], ['train','test'],['blue','orange']):\n",
    "        ax.plot(info_tuple.history[name], color=color)\n",
    "        ax.set_title(f'Learning Curve ({name})')\n",
    "        ax.set_xlabel('Epoch')\n",
    "        ax.set_ylabel('Cost')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(top=0.88)\n",
    "\n",
    "    display.clear_output(wait=True)\n",
    "    display.display(pl.gcf())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Normal(x, mu=0.0, sigma=1.0):\n",
    "    if type(x)==torch.Tensor:\n",
    "        x = x.detach().cpu().numpy()\n",
    "        \n",
    "    res = (1/(sigma * np.sqrt(2 * np.pi)) * np.exp( - (x - mu)**2 / (2 * sigma**2) )).astype(np.float32)\n",
    "    return torch.tensor(res).double().to(device)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define criterion\n",
    "criterion = mse = nn.MSELoss()\n",
    "# criterion = nn.L1Loss()\n",
    "\n",
    "\n",
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "\n",
    "df_list = []  # list of df to merge\n",
    "\n",
    "for phase in ['train', 'test']:\n",
    "    df_list.append(\n",
    "        dataset[phase].target_df\n",
    "    )\n",
    "\n",
    "df = pd.concat(df_list)  #  concat\n",
    "\n",
    "# mean and std from data\n",
    "mu = df.values.mean(0)\n",
    "sigma = df.values.std(0)\n",
    "\n",
    "\n",
    "def get_prob(v):\n",
    "    probs = []\n",
    "    for i in range(v.shape[1]):\n",
    "        hist, bins = np.histogram(df.values[:,i], bins=100)\n",
    "        probs_distribution = hist/len(df)\n",
    "\n",
    "        query = np.array([ min(99,x) for x in np.argmax(bins[None,:] > v[:,i][:,None],1) ])\n",
    "        p = probs_distribution[query]\n",
    "        probs.append(p)\n",
    "\n",
    "    probs = np.array(p)[:,None]\n",
    "\n",
    "    return torch.from_numpy(probs).to(device)\n",
    "\n",
    "#scaled_mse = lambda x,y : torch.mean( torch.from_numpy(1/sigma).to(device) * torch.pow( (x - y), 2) ) \n",
    "# criterion = lambda x,y : torch.mean( torch.pow(1-get_prob(y.detach().cpu().numpy()), 2) * torch.pow( (x - y)/y, 2) )\n",
    "#criterion = lambda x,y : torch.mean( torch.pow(1-get_prob(y.detach().cpu().numpy()), 2) * torch.pow( (x - y)/y, 2) )\n",
    "\n",
    "criterion = lambda x, y : torch.mean( torch.pow( (x - y), 2) )\n",
    "\n",
    "# criterion = lambda x,y : torch.mean( \n",
    "#     torch.pow(1-get_prob(y.detach().cpu().numpy()), 2) * torch.pow(x - y, 2) )\n",
    "\n",
    "# criterion = lambda x, y, alpha : torch.mean( alpha * torch.pow( (x - y), 2) )\n",
    "# criterion = lambda x, y : torch.mean(torch.pow(1-get_prob(y.detach().cpu().numpy()), 2) * torch.pow( (x - y), 2) )\n",
    "# criterion = lambda x, y : torch.mean( torch.abs(torch.log( 1. / (Normal(x, mu, sigma)+1e-7) )) * torch.pow( (x - y), 2) )\n",
    "# criterion = lambda x, y : torch.mean( \n",
    "#     torch.tanh( torch.abs(torch.log( 1. / (Normal(x, mu, sigma)) )) ) * torch.pow( (x - y), 2) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/13 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training loop...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cuda:1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-d1927ae9e967>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphase\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m                     \u001b[0;31m# feed data to network\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m                     \u001b[0m_res\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m                     \u001b[0m_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_res\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_targets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36m_worker\u001b[0;34m(i, module, input, kwargs, device)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m                     \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7dbc3c8decfa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img, decoder_input, greedy)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgreedy\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0mo\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_input\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7dbc3c8decfa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, rnn, initial_state, length)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m             \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0mtopv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtopi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtopk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# get candidates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-7dbc3c8decfa>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, initial_state)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;31m# initial state: (1,1,F), in : (B,T,1), out : (B,T,hidden)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0mlstm_out\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlstm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlstm_out\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# in : (B,T,hidden), out : (B,T,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/torch/lib/python3.6/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    177\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             result = _impl(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 179\u001b[0;31m                            self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    180\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             result = _impl(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Input and hidden tensors are not at the same device, found input tensor at cuda:0 and hidden tensor at cuda:1"
     ]
    }
   ],
   "source": [
    "# cost history saving..\n",
    "history = {'train': [],\n",
    "           'test': []}\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "# Observe that all parameters are being optimized\n",
    "# opt = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "# opt = optim.RMSprop(net.parameters(), lr=1e-2)\n",
    "opt = optim.SGD(net.parameters(), lr=1e-3, momentum=0.9, nesterov=True)\n",
    "# # Decay LR by a factor of 0.1 every 7 epochs\n",
    "scheduler = lr_scheduler.StepLR(opt, step_size=7, gamma=0.1)\n",
    "\n",
    "info = collections.namedtuple(\"monitor_info\",\n",
    "                              \"epoch phase res targets columns avg_loss history\")\n",
    "\n",
    "end_epoch = 10\n",
    "\n",
    "print(\"Start training loop...\")\n",
    "\n",
    "for epoch in range(end_epoch+1):\n",
    "    for phase in ['train','test']:\n",
    "        try:\n",
    "            \n",
    "            if phase=='train':\n",
    "                scheduler.step()\n",
    "                net.train()\n",
    "            elif phase=='test':\n",
    "                net.eval()\n",
    "            \n",
    "            list_res_and_targets = []\n",
    "\n",
    "            running_loss = 0.0\n",
    "            \n",
    "            for batch_item in tqdm(dataloader[phase]):\n",
    "                _inputs, _targets = batch_item['inputs'].to(device), batch_item['targets'].to(device)\n",
    "                \n",
    "                opt.zero_grad()\n",
    "\n",
    "                with torch.set_grad_enabled(phase=='train'):\n",
    "                    # feed data to network\n",
    "                    _res, _ = net.forward(img=_inputs, decoder_input=_targets[:,:-1], greedy=True)\n",
    "                    \n",
    "                    _loss = criterion(_res.double(), _targets[:,1:].double())\n",
    "                    \n",
    "                    _res = _res.detach().cpu().numpy()\n",
    "                    _targets = _targets.detach().cpu().numpy()\n",
    "                    \n",
    "                    list_res_and_targets.append( (_res,_targets[:,1:]) )\n",
    "\n",
    "                    if phase=='train':\n",
    "                        _loss.backward()\n",
    "                        opt.step()\n",
    "\n",
    "                running_loss += _loss.item() * len(_inputs)\n",
    "                            \n",
    "\n",
    "            avg_loss = running_loss / len(dataloader[phase].dataset)\n",
    "            if epoch>0:\n",
    "                history[phase].append(avg_loss)\n",
    "            \n",
    "            res, targets = np.concatenate(list_res_and_targets,1)\n",
    "            #rmse = np.sqrt(np.power(res-targets,2).mean())\n",
    "            rmse = np.sqrt(np.power(dataset[phase].target_scaler.inverse_transform(res)-dataset[phase].target_scaler.inverse_transform(targets),2).mean())\n",
    "            if phase=='test': set_trace()\n",
    "            print(phase, 'loss :', avg_loss, 'rmse :', rmse)\n",
    "            \n",
    "\n",
    "            info_tuple = info(epoch, phase, res, targets, target_columns, avg_loss, history)\n",
    "            \n",
    "            monitor_lerning_process(info_tuple)\n",
    "                \n",
    "                \n",
    "                \n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "\n",
    "\n",
    "plt.close()\n",
    "print(\"Done!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_packed_sequence"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
