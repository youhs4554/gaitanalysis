{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import natsort\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data 1 : URFD\n",
    "- step 1 : pack each directory containing .png files as .avi file (to follow UCF format)\n",
    "- step 2 : re-arange video files according to the class label\n",
    "- step 3 : copy-and-paste UCF clip generation code..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data/FallDownData/URFD_origin/raw'\n",
    "video_files = natsort.natsorted(glob.glob(root + '/*/*'))\n",
    "for video in tqdm(video_files):\n",
    "    prefix, ext = os.path.splitext(video)\n",
    "    save_path = prefix.replace('raw', 'video') + '.avi'\n",
    "    \n",
    "    frame_list = natsort.natsorted(glob.glob(video+'/*'))        \n",
    "    first_frame = cv2.imread(frame_list[0])\n",
    "    out = cv2.VideoWriter(save_path,\n",
    "                          cv2.VideoWriter_fourcc('M','J','P','G'), \n",
    "                          30, (first_frame.shape[:-1][::-1]))\n",
    "    for img_file in frame_list:\n",
    "        img_arr = cv2.imread(img_file)\n",
    "        out.write(img_arr)\n",
    "        \n",
    "    os.system('mkdir -p {}'.format(os.path.dirname(save_path)))\n",
    "    out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# root = '/data/FallDownData/URFD/raw'\n",
    "# video_files = natsort.natsorted(glob.glob(root + '/*/*'))\n",
    "# for video in tqdm(video_files):\n",
    "#     prefix, ext = os.path.splitext(video)\n",
    "#     save_path = prefix.replace('raw', 'video') + '.avi'\n",
    "    \n",
    "#     frames = []\n",
    "    \n",
    "#     cap = cv2.VideoCapture(video)\n",
    "#     frame_height, frame_width = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)), int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    \n",
    "#     out = cv2.VideoWriter(save_path,\n",
    "#                           cv2.VideoWriter_fourcc('M','J','P','G'), \n",
    "#                           30, (frame_width//2,frame_height))\n",
    "    \n",
    "#     while True:\n",
    "#         ret, frame = cap.read()\n",
    "#         if not ret:\n",
    "#             break\n",
    "            \n",
    "#         # left : depth, right : color\n",
    "#         color_frame = frame[:, frame_width//2:]\n",
    "#         out.write(color_frame)\n",
    "\n",
    "#     os.system('mkdir -p {}'.format(os.path.dirname(save_path)))\n",
    "#     out.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data 2 : Multicam FDD\n",
    "- this dataset is bullshit!\n",
    "- syncronization is not matched well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/data/FallDownData/MulticamFD/raw'\n",
    "df = pd.read_csv(os.path.join(os.path.dirname(root), 'Multicam_Annotations.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>camera_reference</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>874</td>\n",
       "      <td>1011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1012</td>\n",
       "      <td>1079</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1080</td>\n",
       "      <td>1108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1109</td>\n",
       "      <td>1285</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>308</td>\n",
       "      <td>374</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  camera_reference  start   end  code\n",
       "0   1                11    874  1011     1\n",
       "1   1                11   1012  1079     6\n",
       "2   1                11   1080  1108     2\n",
       "3   1                11   1109  1285     3\n",
       "4   2                 4    308   374     1"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>camera_reference</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>874</td>\n",
       "      <td>1011</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1012</td>\n",
       "      <td>1079</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1080</td>\n",
       "      <td>1108</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1109</td>\n",
       "      <td>1285</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  camera_reference  start   end  code\n",
       "0   1                11    874  1011     1\n",
       "1   1                11   1012  1079     6\n",
       "2   1                11   1080  1108     2\n",
       "3   1                11   1109  1285     3"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.id==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arange_multicam_dataset(root):\n",
    "    videos = []\n",
    "\n",
    "    for dirpath, dirnames, filenames in os.walk(root):\n",
    "        for fn in filenames:\n",
    "            name, ext = os.path.splitext(fn)\n",
    "            if ext == '.avi':\n",
    "                videos.append(os.path.join(dirpath, fn))\n",
    "\n",
    "\n",
    "    videos = natsort.natsorted(videos)\n",
    "    scenarios = np.unique([os.path.dirname(p) for p in videos])\n",
    "    \n",
    "    for scenario in tqdm(scenarios):\n",
    "        def get_shortest_frame_count():\n",
    "\n",
    "            shortest_frame_count = np.inf\n",
    "\n",
    "            for i in range(1,9):\n",
    "                vpath = os.path.join(scenario, f'cam{i}.avi')\n",
    "                cap = cv2.VideoCapture(vpath)\n",
    "                frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "                if frame_count < shortest_frame_count:\n",
    "                    shortest_frame_count = frame_count\n",
    "\n",
    "            shortest_frame_count = int(shortest_frame_count)\n",
    "\n",
    "            return shortest_frame_count\n",
    "\n",
    "        shortest_frame_count = get_shortest_frame_count()\n",
    "\n",
    "        def get_syncronized_videos():\n",
    "            res = []\n",
    "            for i in range(1,9):\n",
    "                vpath = os.path.join(scenario, f'cam{i}.avi')\n",
    "                cap = cv2.VideoCapture(vpath)\n",
    "                frames = []\n",
    "                while True:\n",
    "                    ret, frame = cap.read()\n",
    "                    if not ret:\n",
    "                        break\n",
    "                    frames.append(frame)\n",
    "\n",
    "                res.append(frames[-shortest_frame_count:])\n",
    "\n",
    "            return np.array(res)\n",
    "\n",
    "        syncronized = get_syncronized_videos()\n",
    "\n",
    "        scenario_id = eval(os.path.basename(scenario).split('chute')[1].lstrip('0'))\n",
    "        scenario_video_home = os.path.dirname(scenario).replace('raw', 'video')\n",
    "\n",
    "        for seg_ix, (start, end, code) in enumerate(df[df.id==scenario_id][[\"start\",\"end\",\"code\"]].values):\n",
    "            segment = syncronized[:, start:end]  # a frame segment\n",
    "\n",
    "            label = 'fall' if code == 2 else 'adl'\n",
    "            scenario_video = os.path.join(scenario_video_home, label)\n",
    "\n",
    "            os.system('mkdir -p {}'.format(scenario_video))\n",
    "\n",
    "            for i in range(1,9):\n",
    "                seg_ix_str = str(seg_ix+1).zfill(2)\n",
    "                vpath = os.path.join(scenario, f'cam{i}.avi')\n",
    "                scenario_indicator = os.path.basename(scenario)\n",
    "\n",
    "                seg_vpath = os.path.join(scenario_video, f'{scenario_indicator}-cam{i}-s{seg_ix_str}.avi')\n",
    "\n",
    "                frame_height, frame_width = segment[i-1][0].shape[:2]\n",
    "\n",
    "                fps = cv2.VideoCapture(vpath).get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "                out = cv2.VideoWriter(seg_vpath,\n",
    "                                  cv2.VideoWriter_fourcc('M','J','P','G'), \n",
    "                                  fps, (frame_width,frame_height))\n",
    "\n",
    "                for frame in segment[i-1]:\n",
    "                    out.write(frame)\n",
    "\n",
    "                    \n",
    "arange_multicam_dataset(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('/data/FallDownData/MulticamFD/video/fall/chute09-cam6-s05.avi')\n",
    "\n",
    "frames = []\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    frames.append(frame)\n",
    "\n",
    "def check_detection_result(img, box):\n",
    "    #bx,by,bw,bh = 307.466186523,196.785614014,86.6007080078,166.478393555\n",
    "    bx,by,bw,bh = box\n",
    "    xmin, ymin, xmax, ymax = int(bx-bw/2), int(by-bh/2), int(bx+bw/2), int(by+bh/2)\n",
    "    return img[ymin:ymax, xmin:xmax]\n",
    "\n",
    "plt.imshow(check_detection_result(frames[16], (370.211120605,174.12197876,88.2487030029,67.7461776733)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(frames[17])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap.get(cv2.CAP_PROP_FPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/torch_data/UCF-101/ucfTrainTestlist/trainlist01.txt') as f:\n",
    "    ucfList = f.readlines()\n",
    "    labels = [ line.strip().split()[1] for line in ucfList ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(labels, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Traintests-plit for cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, LeaveOneOut\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_traintestList(root, annotation_path, random_state=0, n_splits=5):\n",
    "    dataset_name = os.path.basename(os.path.dirname(root.rstrip('/')))\n",
    "    \n",
    "    os.system(f'mkdir -p {annotation_path}')\n",
    "\n",
    "    video_dirs = natsort.natsorted(glob.glob(root + '/*/*'))\n",
    "\n",
    "    np.random.seed(random_state)\n",
    "    np.random.shuffle(video_dirs)\n",
    "\n",
    "    class2idx = {'adl':0, 'fall':1}\n",
    "\n",
    "    formated_video_dirs = np.array([ x[len(root.rstrip('/'))+1:] for x in video_dirs ])\n",
    "    \n",
    "    # split based on scenario\n",
    "#     scenarios = np.array(\n",
    "#         list(set([ os.path.basename(x).split('-')[0] for x in formated_video_dirs ]))\n",
    "#     )\n",
    "\n",
    "    # split based on camera\n",
    "    scenarios = np.array(\n",
    "        natsort.natsorted(list(set([ os.path.basename(x).split('-')[1] for x in formated_video_dirs ]))\n",
    "    ))\n",
    "\n",
    "    loo = LeaveOneOut()\n",
    "    kf = StratifiedKFold(n_splits=n_splits)\n",
    "    \n",
    "    data_to_split = None\n",
    "    if dataset_name == 'URFD':\n",
    "        data_to_split = formated_video_dirs\n",
    "    elif dataset_name == 'MulticamFD':\n",
    "        data_to_split = scenarios    \n",
    "        \n",
    "    def get_train_test_split(train_ix, test_ix):\n",
    "        if dataset_name == 'URFD':\n",
    "            _train, _test = np.array(formated_video_dirs)[train_ix], np.array(formated_video_dirs)[test_ix]\n",
    "        elif dataset_name == 'MulticamFD':\n",
    "            train_scenario_str, test_scenario_str = scenarios[train_ix], scenarios[test_ix]\n",
    "            print(f'[splist-{k}] train : {np.unique(train_scenario_str)}, test : {np.unique(test_scenario_str)}')\n",
    "            \n",
    "            _test = []\n",
    "            for s in test_scenario_str:\n",
    "                _test.append(formated_video_dirs[np.char.find(formated_video_dirs, s) != -1])\n",
    "\n",
    "                \n",
    "            _test = list(itertools.chain(*_test))\n",
    "            _train = list(set(formated_video_dirs)-set(_test))\n",
    "\n",
    "        return _train, _test\n",
    "\n",
    "\n",
    "    for k, (train_ix, test_ix) in enumerate(kf.split(formated_video_dirs, [os.path.dirname(x) for x in formated_video_dirs])):\n",
    "#     for k, (train_ix, test_ix) in enumerate(loo.split(scenarios)):\n",
    "        print()\n",
    "\n",
    "#         _train, _test = get_train_test_split(train_ix, test_ix)\n",
    "        _train, _test = np.array(formated_video_dirs)[train_ix], np.array(formated_video_dirs)[test_ix]\n",
    "    \n",
    "        _train_lab = [ os.path.dirname(x) for x in _train ]\n",
    "        _test_lab = [ os.path.dirname(x) for x in _test ]\n",
    "        print()\n",
    "        print(f'[splist-{k}] train : {np.unique(_train_lab, return_counts=True)}, test : {np.unique(_test_lab, return_counts=True)}')\n",
    "        for _split, _data in zip(['train', 'test'], [_train, _test]):\n",
    "            lines = []\n",
    "            for i in range(len(_data)):\n",
    "                line = os.path.splitext(_data[i])[0] + \" \"\n",
    "                line += str(class2idx[os.path.dirname(_data[i])])\n",
    "\n",
    "                lines.append(line + '\\n')\n",
    "\n",
    "            with open(os.path.join(annotation_path, f\"{_split}list{k+1:02d}.txt\"), 'w') as fp:\n",
    "                fp.writelines(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[splist-0] train : (array(['adl', 'fall'], dtype='<U4'), array([32, 47])), test : (array(['adl', 'fall'], dtype='<U4'), array([ 8, 12]))\n",
      "\n",
      "\n",
      "[splist-1] train : (array(['adl', 'fall'], dtype='<U4'), array([32, 47])), test : (array(['adl', 'fall'], dtype='<U4'), array([ 8, 12]))\n",
      "\n",
      "\n",
      "[splist-2] train : (array(['adl', 'fall'], dtype='<U4'), array([32, 47])), test : (array(['adl', 'fall'], dtype='<U4'), array([ 8, 12]))\n",
      "\n",
      "\n",
      "[splist-3] train : (array(['adl', 'fall'], dtype='<U4'), array([32, 47])), test : (array(['adl', 'fall'], dtype='<U4'), array([ 8, 12]))\n",
      "\n",
      "\n",
      "[splist-4] train : (array(['adl', 'fall'], dtype='<U4'), array([32, 48])), test : (array(['adl', 'fall'], dtype='<U4'), array([ 8, 11]))\n"
     ]
    }
   ],
   "source": [
    "# URFD\n",
    "create_traintestList(root = '/data/FallDownData/URFD/video',\n",
    "                     annotation_path = '/data/FallDownData/URFD/TrainTestlist',\n",
    "                     n_splits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "[splist-0] train : (array(['adl', 'fall'], dtype='<U4'), array([582, 147])), test : (array(['adl', 'fall'], dtype='<U4'), array([146,  37]))\n",
      "\n",
      "\n",
      "[splist-1] train : (array(['adl', 'fall'], dtype='<U4'), array([582, 147])), test : (array(['adl', 'fall'], dtype='<U4'), array([146,  37]))\n",
      "\n",
      "\n",
      "[splist-2] train : (array(['adl', 'fall'], dtype='<U4'), array([582, 148])), test : (array(['adl', 'fall'], dtype='<U4'), array([146,  36]))\n",
      "\n",
      "\n",
      "[splist-3] train : (array(['adl', 'fall'], dtype='<U4'), array([583, 147])), test : (array(['adl', 'fall'], dtype='<U4'), array([145,  37]))\n",
      "\n",
      "\n",
      "[splist-4] train : (array(['adl', 'fall'], dtype='<U4'), array([583, 147])), test : (array(['adl', 'fall'], dtype='<U4'), array([145,  37]))\n"
     ]
    }
   ],
   "source": [
    "# MulticamFD\n",
    "create_traintestList(root = '/data/FallDownData/MulticamFD/video',\n",
    "                     annotation_path = '/data/FallDownData/MulticamFD/TrainTestlist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LeaveOneOut()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
