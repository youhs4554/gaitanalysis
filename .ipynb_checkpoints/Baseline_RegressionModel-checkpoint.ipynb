{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from IPython.core.debugger import set_trace\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pose Output Format (BODY_25)\n",
    "<img src=\"https://github.com/CMU-Perceptual-Computing-Lab/openpose/raw/master/doc/media/keypoints_pose_25.png\" width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check cuda.is_available ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda_available : True, device : cuda:0\n"
     ]
    }
   ],
   "source": [
    "cuda_available = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"cuda_available : {}, device : {}\".format(cuda_available, device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_pairs = [\n",
    "              #(1,8),\n",
    "              #(1,2),\n",
    "              #(1,5),\n",
    "              #(2,3),\n",
    "              #(3,4),\n",
    "              #(5,6),\n",
    "              #(6,7),\n",
    "              (8,9),\n",
    "              (9,10),\n",
    "              (10,11),\n",
    "              (8,12),\n",
    "              (12,13),\n",
    "              (13,14),\n",
    "              #(1,0),\n",
    "              #(0,15),\n",
    "              #(15,17),\n",
    "              #(0,16),\n",
    "              #(16,18),\n",
    "              #(2,17),\n",
    "              #(5,18),\n",
    "              (14,19),\n",
    "              (19,20),\n",
    "              (14,21),\n",
    "              (11,22),\n",
    "              (22,23),\n",
    "              (11,24)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Dataset & DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pixiedust": {
     "displayParams": {}
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class GAITDataset(Dataset):\n",
    "    def __init__(self, keypoints_csv_file, targets_csv_file, maxlen=200):\n",
    "        self.keypoints_frame = pd.read_pickle(keypoints_csv_file)\n",
    "        self.targets_frame = pd.read_pickle(targets_csv_file)\n",
    "        self.pids = list(set(self.keypoints_frame.index))\n",
    "        self.maxlen = maxlen\n",
    "        self.bottom_ixs = list(set(itertools.chain(*part_pairs)))\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.targets_frame)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        keypoints_seq = np.c_[list(np.asarray(x) for x in self.keypoints_frame.loc[self.pids[idx], 'person_0'].values)]\n",
    "        \n",
    "        # filter body parts by its indices\n",
    "        keypoints_tmp = keypoints_seq.reshape(-1,25,3) # (time_stamps,25,3)\n",
    "        \n",
    "        # select bottom parts\n",
    "        keypoints_seq = keypoints_tmp[:,self.bottom_ixs,:].reshape(len(keypoints_seq), -1)\n",
    "        \n",
    "        # zero padding\n",
    "        keypoints_seq = np.pad(keypoints_seq, ((0,self.maxlen-len(keypoints_seq)),(0,0)),\n",
    "                                               'constant', constant_values=0).transpose(1,0)\n",
    "        \n",
    "        targets = self.targets_frame.loc[self.pids[idx]].values\n",
    "        \n",
    "        sample = {'keypoints_seq': torch.tensor(keypoints_seq, dtype=torch.float32).cpu(),\n",
    "                  'targets': torch.tensor(targets, dtype=torch.float32).cpu()}\n",
    "        \n",
    "        return sample\n",
    "\n",
    "# dataset path\n",
    "keypoints_csv_file= \"./example_data/keypoints/keypoints_df.pkl\"\n",
    "targets_csv_file = \"./example_data/targets/targets_df.pkl\"\n",
    "\n",
    "\n",
    "mydataset = GAITDataset(keypoints_csv_file, targets_csv_file)\n",
    "\n",
    "dataloader = DataLoader(mydataset, \n",
    "                        batch_size=5,\n",
    "                        shuffle=True,\n",
    "                        num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([17])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mydataset[0]['targets'].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv1d(nn.Conv1d):\n",
    "    def __init__(self, in_channels,\n",
    "                       out_channels,\n",
    "                       kernel_size,\n",
    "                       stride=1,\n",
    "                       padding=0,\n",
    "                       dilation=1,\n",
    "                       groups=1,\n",
    "                       bias=True,\n",
    "                       padding_type='same'):\n",
    "        \n",
    "        super(Conv1d, self).__init__(in_channels,\n",
    "                                     out_channels,\n",
    "                                     kernel_size,\n",
    "                                     stride,\n",
    "                                     padding,\n",
    "                                     dilation,\n",
    "                                     groups,\n",
    "                                     bias)\n",
    "        \n",
    "        self.padding_type = padding_type\n",
    "    \n",
    "    def forward(self, x):\n",
    "        _, _, input_length = x.size()\n",
    "        \n",
    "        if self.padding_type == 'same':\n",
    "            padding_need = int((input_length * (self.stride[0]-1) + self.kernel_size[0] - self.stride[0]) / 2)\n",
    "        \n",
    "        return F.conv1d(x, self.weight, self.bias, self.stride, \n",
    "                        padding_need, self.dilation, self.groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, C, highway=True):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.highway = highway\n",
    "        \n",
    "        # pre-define bottle-neck structure\n",
    "        \n",
    "        # conv_1x1_a : reduce number of channels by factor of 4 (output_channel = C/4)\n",
    "        self.conv_1x1_a = Conv1d(C, int(C/4), kernel_size=1, stride=1, padding_type='same')\n",
    "        self.bn_1x1_a = nn.BatchNorm1d(int(C/4))\n",
    "        \n",
    "        # conv_3x3_b : more wide receptive field (output_channel = C/4)\n",
    "        self.conv_3x3_b = Conv1d(int(C/4), int(C/4), kernel_size=3, stride=1, padding_type='same')\n",
    "        self.bn_3x3_b = nn.BatchNorm1d(int(C/4))\n",
    "        \n",
    "        # conv_1x1_c : recover org channel C (output_channel = C)\n",
    "        self.conv_1x1_c = Conv1d(int(C/4), C, kernel_size=1, stride=1, padding_type='same')\n",
    "        self.bn_1x1_c = nn.BatchNorm1d(C)\n",
    "        \n",
    "        # conv_1x1_g : gating for highway network\n",
    "        self.conv_1x1_g = Conv1d(C, C, kernel_size=1, stride=1, padding_type='same')\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x : size = (batch, C, maxlen)\n",
    "        '''\n",
    "        res = x        \n",
    "    \n",
    "        # 1x1_a (C/4)\n",
    "        x = self.conv_1x1_a(x)\n",
    "        x = self.bn_1x1_a(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # 3x3_b (C/4)\n",
    "        x = self.conv_3x3_b(x)\n",
    "        x = self.bn_3x3_b(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        # 1x1_c (C)\n",
    "        x = self.conv_1x1_c(x)\n",
    "        x = self.bn_1x1_c(x)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        \n",
    "        if self.highway:\n",
    "            # gating mechanism from \"highway network\"\n",
    "            \n",
    "            # gating factors controll intensity between x and f(x)\n",
    "            # gating = 1.0 (short circuit) --> output is identity (same as initial input)\n",
    "            # gating = 0.0 (open circuit)--> output is f(x) (case of non-residual network)\n",
    "            gating = F.sigmoid(self.conv_1x1_g(x))\n",
    "                                   \n",
    "            # apply gating mechanism\n",
    "            x = gating * res + (1.0 - gating) * x\n",
    "            \n",
    "        else:\n",
    "            # normal residual ops (addition)\n",
    "            x = x + res\n",
    "\n",
    "        # apply relu for final output\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class View(nn.Module):\n",
    "    def __init__(self, *shape):\n",
    "        super(View, self).__init__()\n",
    "        self.shape = shape\n",
    "    def forward(self, x):\n",
    "        return x.view(*self.shape)\n",
    "    \n",
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, target_size, n_residual_blocks=4, residual_pooling_indices=range(0,4,2), C=64):\n",
    "        assert max(residual_pooling_indices) < n_residual_blocks, \"maxvalue of residual_pooling_indices ({}) cannot exceed n_residual_blocks ({})\".format(max(residual_pooling_indices), n_residual_blocks)\n",
    "        assert min(residual_pooling_indices) >= 0 , \"minvalue of residual_pooling_indices ({}) cannot be smaller than 0\".format(min(residual_pooling_indices))\n",
    "\n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.target_size = target_size\n",
    "        \n",
    "        residual_blocks = []\n",
    "        pooling_cnt = 0 \n",
    "        for i in range(n_residual_blocks):\n",
    "            residual_blocks.append(ResidualBlock(C))\n",
    "            if i in residual_pooling_indices:\n",
    "                # every 2 residual, block pooling out!\n",
    "                residual_blocks.append(nn.MaxPool1d((2,)))\n",
    "                pooling_cnt += 1\n",
    "\n",
    "        length_after_pooling = int(mydataset.maxlen/(2**pooling_cnt))\n",
    "\n",
    "        self.model = nn.Sequential(Conv1d(input_size, C, kernel_size=1, stride=1, padding_type='same'),\n",
    "                                   nn.BatchNorm1d(C),\n",
    "                                   nn.ReLU(),\n",
    "                                   *residual_blocks,\n",
    "                                   View(-1,64 * length_after_pooling),\n",
    "                                   nn.Linear(64 * length_after_pooling, 256),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(256, 64),\n",
    "                                   nn.ReLU(),\n",
    "                                   nn.Linear(64, target_size)\n",
    "                                   )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        '''\n",
    "            x : size = (batch, input_size, maxlen)\n",
    "        '''\n",
    "        return self.model(x)\n",
    "            \n",
    "net = Net(input_size=len(mydataset.bottom_ixs)*3,\n",
    "          target_size=len(mydataset.targets_frame.columns), n_residual_blocks=4, residual_pooling_indices=(0,2), C=64)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    net = nn.DataParallel(net)\n",
    "else:\n",
    "    print(\"Single GPU mode\")\n",
    "\n",
    "net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define criterion\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "import torch.optim as optim\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-4)\n",
    "\n",
    "for epoch in range(500):\n",
    "    running_loss = 0.0\n",
    "    for idx, batch_item in enumerate(dataloader):\n",
    "        net.train()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        input, target = batch_item['keypoints_seq'].to(device), batch_item['targets'].to(device)\n",
    "        \n",
    "        # feed data to network\n",
    "        output = net(input)\n",
    "\n",
    "        # compute loss\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        optimizer.step()\n",
    "\n",
    "    steps_per_epoch = len(dataloader.dataset)/dataloader.batch_size\n",
    "    avg_loss = running_loss / steps_per_epoch\n",
    "    print('========================================================')\n",
    "    print('EPOCH : {}, AVG_MSE : {:.4f}'.format(epoch, avg_loss))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
